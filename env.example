# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_GRPC=false
QDRANT_HNSW_M=16
QDRANT_HNSW_EF_CONSTRUCT=200
QDRANT_HNSW_EF_SEARCH=200
QDRANT_HNSW_FULL_SCAN_THRESHOLD=10000

# BGE-M3 Embeddings Configuration
EMBEDDINGS_BACKEND=auto
EMBEDDING_DEVICE=auto
EMBEDDING_MAX_LENGTH_QUERY=512
EMBEDDING_MAX_LENGTH_DOC=2048
EMBEDDING_BATCH_SIZE=16
SPARSE_BATCH_SIZE=32
DENSE_BATCH_SIZE=16
ADAPTIVE_BATCHING=true
EMBEDDING_NORMALIZE=true
EMBEDDING_USE_COLBERT=false
EMBEDDING_USE_FP16=true

# Sparse vectors configuration (handled by BGE-M3)
USE_SPARSE=true

# LLMs
DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat   # проверьте актуальное имя модели у провайдера

YANDEX_API_URL=https://llm.api.cloud.yandex.net/v1
YANDEX_CATALOG_ID=b1gri82o59t1rin7curn
YANDEX_API_KEY=
# YANDEX_MODEL — идентификатор модели/семейства (уточните на вашем аккаунте)
YANDEX_MODEL=yandexgpt
YANDEX_MAX_TOKENS=4000

# Default LLM provider (какой провайдер использовать по умолчанию)
# Допустимые значения: YANDEX | GPT5 | DEEPSEEK
# Примеры:
# DEFAULT_LLM=YANDEX   # использовать YandexGPT 5.1 Pro
# DEFAULT_LLM=GPT5     # использовать GPT-5 (например, gpt-5-mini)
# DEFAULT_LLM=DEEPSEEK # использовать Deepseek
DEFAULT_LLM=YANDEX
CORE_OUTPUTS_FORMAT=markdown

# GPT-5 (пример для OpenAI-совместимого Chat Completions)
# Если используете OpenAI:
#   GPT5_API_URL=https://api.openai.com/v1/chat/completions
#   GPT5_MODEL=gpt-5-mini
# Если используете Azure OpenAI (пример):
#   GPT5_API_URL=https://<resource>.openai.azure.com/openai/deployments/<deployment>/chat/completions?api-version=2024-02-01
#   GPT5_MODEL=<deployment>
GPT5_API_URL=
GPT5_API_KEY=
GPT5_MODEL=

# Telegram
# TELEGRAM_BOT_TOKEN — токен бота
# TELEGRAM_POLL_INTERVAL — пауза (сек) между попытками при ошибках long polling
TELEGRAM_BOT_TOKEN=
TELEGRAM_POLL_INTERVAL=1.0
CONNECTORS_TELEGRAM_FORMAT=HTML
TELEGRAM_HTML_ALLOWLIST=

# Retrieval config
# Весовая схема гибридного поиска (RRF):
#   HYBRID_DENSE_WEIGHT — вклад dense
#   HYBRID_SPARSE_WEIGHT — вклад sparse
#   RRF_K — параметр RRF
#   RERANK_TOP_N — финальный топ после реранка
HYBRID_DENSE_WEIGHT=0.5
HYBRID_SPARSE_WEIGHT=0.5
RERANK_TOP_N=10
RRF_K=60

# Reranker (BGE-reranker-v2-m3 на GPU)
# RERANKER_MODEL — имя модели в HuggingFace/FlagEmbedding
# RERANKER_DEVICE — cuda для GPU, cpu для CPU
# RERANKER_THREADS — число CPU-потоков (игнорируется на GPU)
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
RERANKER_DEVICE=cuda
RERANKER_THREADS=12

# Auto-Merge Configuration
# Автоматическое объединение соседних чанков одного документа после rerank
# для предоставления LLM более широкого контекста в рамках token budget
# RETRIEVAL_AUTO_MERGE_ENABLED — включить/выключить авто-слияние (true|false)
# RETRIEVAL_AUTO_MERGE_MAX_TOKENS — максимальный размер объединённого окна в токенах
#   Рекомендуется: 1200-2000 для стандартных запросов, меньше для экономии контекста
# RETRIEVAL_AUTO_MERGE_USE_TIKTOKEN — использовать tiktoken для точной оценки токенов (true|false)
#   При false использует быструю эвристику len//4
#   ВАЖНО: требует установки tiktoken (pip install tiktoken==0.8.0)
# RETRIEVAL_CACHE_MAXSIZE — максимальное количество документов в кеше
# RETRIEVAL_CACHE_TTL — время жизни кеша в секундах
#   ВАЖНО: TTL работает только если установлен cachetools (pip install cachetools==5.5.0)
RETRIEVAL_AUTO_MERGE_ENABLED=true
RETRIEVAL_AUTO_MERGE_MAX_TOKENS=1200
RETRIEVAL_AUTO_MERGE_USE_TIKTOKEN=false
RETRIEVAL_CACHE_MAXSIZE=1000
RETRIEVAL_CACHE_TTL=300

# Qdrant Scroll Configuration
# QDRANT_SCROLL_BATCH_SIZE — размер батча при scroll-запросах (получение всех чанков документа)
QDRANT_SCROLL_BATCH_SIZE=64

# GPU Configuration (для AMD Radeon RX 6700 XT)
# GPU_ENABLED — включить GPU-ускорение
# GPU_DEVICE — номер GPU устройства (0 для первой карты)
# GPU_MEMORY_FRACTION — доля памяти GPU для использования (0.0-1.0)
GPU_ENABLED=true
GPU_DEVICE=0
GPU_MEMORY_FRACTION=0.8

# ONNX Runtime provider selection for embeddings/reranker (Windows/DirectML)
# Допустимые значения:
#   auto — предпочесть DmlExecutionProvider, при недоступности упасть на CPU
#   dml  — принудительно использовать DmlExecutionProvider (если доступен)
#   cpu  — принудительно CPUExecutionProvider
ONNX_PROVIDER=auto

# ===== ПЕРЕИНДЕКСАЦИЯ =====
# Параметры для оптимальной переиндексации с BGE-M3

# Рекомендуемые настройки для AMD RX 6700 XT (Windows)
# EMBEDDINGS_BACKEND=hybrid
# EMBEDDING_BATCH_SIZE=32
# EMBEDDING_USE_FP16=true

# Рекомендуемые настройки для NVIDIA GPU (Linux/Windows)
# EMBEDDINGS_BACKEND=bge
# EMBEDDING_BATCH_SIZE=16
# EMBEDDING_USE_FP16=true

# Рекомендуемые настройки для CPU only
# EMBEDDINGS_BACKEND=onnx
# EMBEDDING_BATCH_SIZE=8
# EMBEDDING_USE_FP16=false

# Команды переиндексации:
# python scripts/reindex.py --sparse                    # Рекомендуемый способ
# python scripts/reindex.py --sparse --backend=hybrid   # Принудительно hybrid
# python scripts/reindex.py --sparse --batch-size=32    # Увеличенный батч для GPU
# python -m ingestion.pipeline                          # Альтернативный способ

# Ingestion
# CRAWL_START_URL — корневой URL портала
CRAWL_START_URL=https://docs-chatcenter.edna.ru/
CRAWL_CONCURRENCY=8
CRAWL_TIMEOUT_S=30
CRAWL_MAX_PAGES=0
CRAWL_DELAY_MS=800
CRAWL_JITTER_MS=400
# Комма-разделённые префиксы URL, которые не обходить (deny-list)
# CRAWL_DENY_PREFIXES=/docs/api/

# Enhanced Chunker Configuration
SEMANTIC_CHUNKER_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
SEMANTIC_CHUNKER_THRESHOLD=0.7
SEMANTIC_CHUNKER_OVERLAP_SIZE=50

# Enhanced Crawler Configuration
CRAWLER_STRATEGY=jina
CRAWLER_MAX_RETRIES=3
CRAWLER_BACKOFF_FACTOR=1.5
CRAWLER_RATE_LIMIT_RPS=2.0
CRAWLER_RATE_LIMIT_BURST=5
MAX_CRAWL_DURATION_MINUTES=60

# Quality and Validation Settings
MIN_CHUNK_WORDS=5
MAX_PARAGRAPH_TOKENS=1000
DEDUPLICATION_ENABLED=true

# Security and Limits
MAX_PAGE_SIZE_MB=10
MAX_TOTAL_PAGES=10000
MAX_MEMORY_USAGE_MB=2048

# Chunking parameters (optimized for BGE-M3)
# Рекомендации BGE-M3: 512 токенов ±20% (410-614)
CHUNK_MIN_TOKENS=410
CHUNK_MAX_TOKENS=614
EMBEDDING_DIM=1024
QDRANT_COLLECTION=chatcenter_docs

# Chunking Strategy
# CHUNK_STRATEGY: simple | adaptive
CHUNK_STRATEGY=adaptive

# Adaptive Chunker Parameters
# Пороги кластеров по длине документа (в словах): short/long
ADAPTIVE_SHORT_THRESHOLD=300
ADAPTIVE_LONG_THRESHOLD=1000
# Размеры и overlap
ADAPTIVE_MEDIUM_SIZE=512
ADAPTIVE_MEDIUM_OVERLAP=100
ADAPTIVE_LONG_SIZE=800
ADAPTIVE_LONG_OVERLAP=160
# Объединять параграфы короче N токенов
ADAPTIVE_MERGE_SHORT_PARAGRAPH_TOKENS=50

# RAGAS Quality Evaluation
ENABLE_RAGAS_EVALUATION=true
RAGAS_EVALUATION_SAMPLE_RATE=0.1
RAGAS_BATCH_SIZE=10
RAGAS_ASYNC_TIMEOUT=30

# RAGAS LLM Backend Selection
# Выберите, какой LLM использовать для RAGAS оценки:
# - yandexgpt (по умолчанию, использует YANDEX_API_KEY)
# - deepseek (использует DEEPSEEK_API_KEY, OpenAI-совместимый)
# - openai (требует OPENAI_API_KEY)
# - gpt5 (требует GPT5_API_KEY)
RAGAS_LLM_BACKEND=yandexgpt

# OpenAI Configuration (опционально для RAGAS)
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# Quality Database
QUALITY_DB_ENABLED=true
DATABASE_URL=sqlite:///data/quality_interactions.db

# Quality Metrics
ENABLE_QUALITY_METRICS=true
QUALITY_PREDICTION_THRESHOLD=0.7
