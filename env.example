# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_HNSW_M=16
QDRANT_HNSW_EF_CONSTRUCT=200
QDRANT_HNSW_EF_SEARCH=200
QDRANT_HNSW_FULL_SCAN_THRESHOLD=10000

# Ollama (Embeddings)
OLLAMA_URL=http://localhost:11434
EMBEDDING_MODEL_TYPE=BGE-M3
EMBEDDING_MODEL_NAME=bge-m3:latest

# Sparse Embeddings (FlagEmbedding service)
SPARSE_SERVICE_URL=http://localhost:8001
USE_SPARSE=true

# LLMs
DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat   # проверьте актуальное имя модели у провайдера

YANDEX_API_URL=https://llm.api.cloud.yandex.net/v1
YANDEX_CATALOG_ID=b1gri82o59t1rin7curn
YANDEX_API_KEY=
# YANDEX_MODEL — идентификатор модели/семейства (уточните на вашем аккаунте)
YANDEX_MODEL=yandexgpt
YANDEX_MAX_TOKENS=4000

# Default LLM provider (какой провайдер использовать по умолчанию)
# Допустимые значения: YANDEX | GPT5 | DEEPSEEK
# Примеры:
# DEFAULT_LLM=YANDEX   # использовать YandexGPT 5.1 Pro
# DEFAULT_LLM=GPT5     # использовать GPT-5 (например, gpt-5-mini)
# DEFAULT_LLM=DEEPSEEK # использовать Deepseek
DEFAULT_LLM=YANDEX

# GPT-5 (пример для OpenAI-совместимого Chat Completions)
# Если используете OpenAI:
#   GPT5_API_URL=https://api.openai.com/v1/chat/completions
#   GPT5_MODEL=gpt-5-mini
# Если используете Azure OpenAI (пример):
#   GPT5_API_URL=https://<resource>.openai.azure.com/openai/deployments/<deployment>/chat/completions?api-version=2024-02-01
#   GPT5_MODEL=<deployment>
GPT5_API_URL=
GPT5_API_KEY=
GPT5_MODEL=

# Telegram
# TELEGRAM_BOT_TOKEN — токен бота
# TELEGRAM_POLL_INTERVAL — пауза (сек) между попытками при ошибках long polling
TELEGRAM_BOT_TOKEN=
TELEGRAM_POLL_INTERVAL=1.0

# Retrieval config
# Весовая схема гибридного поиска (RRF):
#   HYBRID_DENSE_WEIGHT — вклад dense
#   HYBRID_SPARSE_WEIGHT — вклад sparse
#   RRF_K — параметр RRF
#   RERANK_TOP_N — финальный топ после реранка
HYBRID_DENSE_WEIGHT=0.5
HYBRID_SPARSE_WEIGHT=0.5
RERANK_TOP_N=10
RRF_K=60

# Reranker (BGE-reranker-v2-m3 на GPU)
# RERANKER_MODEL — имя модели в HuggingFace/FlagEmbedding
# RERANKER_DEVICE — cuda для GPU, cpu для CPU
# RERANKER_THREADS — число CPU-потоков (игнорируется на GPU)
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
RERANKER_DEVICE=cuda
RERANKER_THREADS=12

# GPU Configuration (для AMD Radeon RX 6700 XT)
# GPU_ENABLED — включить GPU-ускорение
# GPU_DEVICE — номер GPU устройства (0 для первой карты)
# GPU_MEMORY_FRACTION — доля памяти GPU для использования (0.0-1.0)
GPU_ENABLED=true
GPU_DEVICE=0
GPU_MEMORY_FRACTION=0.8

# ONNX Runtime provider selection for embeddings/reranker (Windows/DirectML)
# Допустимые значения:
#   auto — предпочесть DmlExecutionProvider, при недоступности упасть на CPU
#   dml  — принудительно использовать DmlExecutionProvider (если доступен)
#   cpu  — принудительно CPUExecutionProvider
ONNX_PROVIDER=auto

# BGE-M3 Embeddings Configuration
# Выбор бэкенда для эмбеддингов: auto|onnx|bge|hybrid
# auto - автоматический выбор оптимальной стратегии (рекомендуется)
# onnx - использовать ONNX Runtime (поддерживает DirectML на Windows/AMD)
# bge - использовать нативный BGE-M3 через FlagEmbedding (CPU/CUDA)
# hybrid - dense через ONNX (GPU), sparse через BGE-M3 (CPU)
EMBEDDINGS_BACKEND=auto

# Устройство для эмбеддингов: auto|cpu|cuda|directml
# auto - автоматический выбор
# cpu - принудительно CPU
# cuda - принудительно CUDA (NVIDIA)
# directml - принудительно DirectML (Windows/AMD, только для ONNX)
EMBEDDING_DEVICE=auto

# Оптимизация длины токенов
EMBEDDING_MAX_LENGTH_QUERY=512     # Короткие запросы пользователей
EMBEDDING_MAX_LENGTH_DOC=1024      # Чанки документации при индексации
EMBEDDING_BATCH_SIZE=16            # Размер батча для обработки

# Дополнительные настройки
EMBEDDING_NORMALIZE=true           # Нормализация векторов для лучшего поиска
EMBEDDING_USE_COLBERT=false        # ColBERT векторы (только для специальных задач)
EMBEDDING_USE_FP16=true           # Половинная точность для экономии памяти (только GPU)

# ===== ПЕРЕИНДЕКСАЦИЯ =====
# Параметры для оптимальной переиндексации с BGE-M3

# Рекомендуемые настройки для AMD RX 6700 XT (Windows)
# EMBEDDINGS_BACKEND=hybrid
# EMBEDDING_BATCH_SIZE=32
# EMBEDDING_USE_FP16=true

# Рекомендуемые настройки для NVIDIA GPU (Linux/Windows)
# EMBEDDINGS_BACKEND=bge
# EMBEDDING_BATCH_SIZE=16
# EMBEDDING_USE_FP16=true

# Рекомендуемые настройки для CPU only
# EMBEDDINGS_BACKEND=onnx
# EMBEDDING_BATCH_SIZE=8
# EMBEDDING_USE_FP16=false

# Команды переиндексации:
# python scripts/reindex.py --sparse                    # Рекомендуемый способ
# python scripts/reindex.py --sparse --backend=hybrid   # Принудительно hybrid
# python scripts/reindex.py --sparse --batch-size=32    # Увеличенный батч для GPU
# python -m ingestion.pipeline                          # Альтернативный способ

# Ingestion
# CRAWL_START_URL — корневой URL портала
# CRAWL_CONCURRENCY — будущая настройка параллелизма (пока не используется)
# CHUNK_* — пороги чанкинга (в «токенах» ~ словах)
CRAWL_START_URL=https://docs-chatcenter.edna.ru/
CRAWL_CONCURRENCY=8
CRAWL_TIMEOUT_S=30
CRAWL_MAX_PAGES=0
CRAWL_DELAY_MS=800
CRAWL_JITTER_MS=400
# Комма-разделённые префиксы URL, которые не обходить (deny-list)
# CRAWL_DENY_PREFIXES=/docs/api/
CHUNK_MIN_TOKENS=120
CHUNK_MAX_TOKENS=600
EMBEDDING_DIM=1024
QDRANT_COLLECTION=chatcenter_docs
