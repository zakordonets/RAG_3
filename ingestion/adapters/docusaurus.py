"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è Docusaurus –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (—Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞)
"""

from pathlib import Path
from typing import Iterable, Dict, Any, Optional, Set
from loguru import logger

from .base import SourceAdapter, RawDoc
from ingestion.crawlers.docusaurus_fs_crawler import crawl_docs
from ingestion.metadata.docusaurus import DocusaurusMetadataMapper


class DocusaurusAdapter(SourceAdapter):
    """
    –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ Docusaurus –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π docusaurus_fs_crawler –¥–ª—è —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–≥–æ –æ–±—Ö–æ–¥–∞
    —Ñ–∞–π–ª–æ–≤ .md/.mdx –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Ö –≤ RawDoc —Ñ–æ—Ä–º–∞—Ç.
    """

    def __init__(
        self,
        docs_root: str,
        site_base_url: str = "https://docs-chatcenter.edna.ru",
        site_docs_prefix: str = "/docs",
        drop_prefix_all_levels: bool = True,
        max_pages: int = None,
        top_level_meta: Optional[Dict[str, Dict[str, str]]] = None,
        metadata_mapper: Optional[DocusaurusMetadataMapper] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–¥–∞–ø—Ç–µ—Ä Docusaurus.

        Args:
            docs_root: –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
            site_base_url: –ë–∞–∑–æ–≤—ã–π URL —Å–∞–π—Ç–∞
            site_docs_prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ URL
            drop_prefix_all_levels: –£–¥–∞–ª—è—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –Ω–∞ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω—è—Ö
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            top_level_meta: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ—Ä—Ö–Ω–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            metadata_mapper: –ú–∞–ø–ø–µ—Ä –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π
        """
        self.docs_root = Path(docs_root)
        self.site_base_url = site_base_url
        self.max_pages = max_pages
        self.site_docs_prefix = site_docs_prefix
        self.drop_prefix_all_levels = drop_prefix_all_levels
        self.top_level_meta = top_level_meta or {}
        self.metadata_mapper = metadata_mapper
        self._top_level_meta_keys: Set[str] = set()
        for meta in self.top_level_meta.values():
            self._top_level_meta_keys.update(meta.keys())

        if not self.docs_root.exists():
            raise ValueError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {docs_root} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

    def iter_documents(self) -> Iterable[RawDoc]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ç–æ–∫ —Å—ã—Ä—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ Docusaurus —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã.

        Yields:
            RawDoc: –°—ã—Ä–æ–π –¥–æ–∫—É–º–µ–Ω—Ç —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —Ñ–∞–π–ª–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        logger.info(
            "–ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Docusaurus –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ {} (site={}, prefix={})",
            self.docs_root,
            self.site_base_url,
            self.site_docs_prefix or "/"
        )
        if self.top_level_meta:
            logger.info(
                "–ü–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {}",
                ", ".join(sorted(self.top_level_meta.keys()))
            )

        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
        all_items = list(crawl_docs(
            docs_root=self.docs_root,
            site_base_url=self.site_base_url,
            site_docs_prefix=self.site_docs_prefix,
            drop_prefix_all_levels=self.drop_prefix_all_levels,
            top_level_meta=self.top_level_meta if self.top_level_meta else None,
        ))
        total_files = len(all_items)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω max_pages
        if self.max_pages and self.max_pages < total_files:
            all_items = all_items[:self.max_pages]
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {total_files} —Ñ–∞–π–ª–æ–≤, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {self.max_pages} –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        else:
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {total_files} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")

        # –¢–µ–ø–µ—Ä—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
        actual_files = len(all_items)
        for file_idx, item in enumerate(all_items, 1):

            try:
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –Ω–∞ –≤–∞–∂–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö
                if file_idx % 10 == 0 or file_idx <= 5 or file_idx > actual_files - 5:
                    logger.info(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª {file_idx}/{actual_files}: {item.abs_path.name}")

                # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
                content_bytes = item.abs_path.read_bytes()

                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π URI
                uri = f"file://{item.abs_path}"

                # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                meta = {
                    "rel_path": item.rel_path,
                    "site_url": item.site_url,
                    "dir_meta": item.dir_meta,
                    "mtime": item.mtime,
                    "file_extension": item.abs_path.suffix,
                    "source": "docusaurus"
                }
                if "top_level_dir" in item.dir_meta:
                    meta["top_level_dir"] = item.dir_meta["top_level_dir"]
                if self._top_level_meta_keys:
                    for key in self._top_level_meta_keys:
                        if key in item.dir_meta:
                            meta[key] = item.dir_meta[key]
                if self.metadata_mapper:
                    mapped = self.metadata_mapper.map_metadata(item.rel_path, item.dir_meta)
                    for key, value in mapped.items():
                        if value is not None:
                            meta[key] = value

                # –°–æ–∑–¥–∞–µ–º RawDoc
                raw_doc = RawDoc(
                    uri=uri,
                    abs_path=item.abs_path,
                    bytes=content_bytes,
                    meta=meta
                )

                yield raw_doc

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {item.abs_path}: {e}")
                continue

        logger.success(f"‚úÖ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_files} —Ñ–∞–π–ª–æ–≤")

        logger.info(f"–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files}")

    def get_source_name(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
        return "docusaurus"
