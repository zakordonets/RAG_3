from __future__ import annotations

from typing import Any
from loguru import logger
from tqdm import tqdm
from ingestion.crawler import crawl, crawl_mkdocs_index, crawl_sitemap
from ingestion.parsers import parse_api_documentation, parse_release_notes, parse_faq_content, parse_guides
from ingestion.chunker import chunk_text, text_hash
from ingestion.indexer import upsert_chunks


def classify_page(url: str) -> str:
    low = url.lower()
    if "faq" in low:
        return "faq"
    if "api" in low:
        return "api"
    if "release" in low or "changelog" in low:
        return "release_notes"
    return "guide"


def crawl_and_index(incremental: bool = True) -> dict[str, Any]:
    """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –∫—Ä–∞—É–ª–∏–Ω–≥ ‚Üí —á–∞–Ω–∫–∏–Ω–≥ ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ ‚Üí upsert –≤ Qdrant.
    incremental: –µ—Å–ª–∏ True ‚Äî –≤ –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å hash –∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –Ω–µ–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –∏ —á–∞–Ω–∫–∞–º.
    """
    # 0) –ï—Å–ª–∏ –µ—Å—Ç—å sitemap.xml ‚Äî —Å–æ–±–µ—Ä—ë–º —Å–ø–∏—Å–æ–∫ URL –∏ —Å–∫–∞—á–∞–µ–º –æ–±—ã—á–Ω—ã–º HTTP
    urls = crawl_sitemap()
    pages: list[dict] = []
    if urls:
        for u in urls:
            try:
                sub = crawl(start_url=u, strategy="jina")
                pages.extend(sub)
            except Exception:
                pass
    # 1) –§–æ–ª–±—ç–∫: –µ—Å–ª–∏ sitemap –ø—É—Å—Ç, –≤–æ–∑—å–º—ë–º –∫–æ—Ä–µ–Ω—å —á–µ—Ä–µ–∑ Jina
    if not pages:
        pages = crawl(strategy="jina")
    if not pages:
        # 2) MkDocs index
        pages = crawl_mkdocs_index()
    if not pages:
        # 3) –§–æ–ª–±—ç–∫: –±—Ä–∞—É–∑–µ—Ä–Ω—ã–π –æ–±—Ö–æ–¥
        pages = crawl(strategy="browser")
    total_chunks = 0
    with tqdm(total=len(pages), desc="Indexing") as pbar:
        for p in pages:
            url = p["url"]
            html = p.get("html") or ""
            raw_text = p.get("text")
            page_type = classify_page(url)

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–æ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞)
            if raw_text:
                text = raw_text
                title = p.get("title")
            else:
                parsed = parse_guides(html)
                text = parsed.get("text") or html
                title = parsed.get("title")
            chunks_text = chunk_text(text)
            chunks = []
            for ct in chunks_text:
                chunks.append({
                    "text": ct,
                    "payload": {
                        "url": url,
                        "page_type": page_type,
                        "source": "docs-site",
                        "language": "ru",
                        "title": title,
                        "text": ct,
                    },
                })
            total_chunks += upsert_chunks(chunks)
            pbar.update(1)
    return {"pages": len(pages), "chunks": total_chunks}


if __name__ == "__main__":
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å BGE-M3 unified embeddings...")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    from app.config import CONFIG
    logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:")
    logger.info(f"  EMBEDDINGS_BACKEND: {CONFIG.embeddings_backend}")
    logger.info(f"  EMBEDDING_DEVICE: {CONFIG.embedding_device}")
    logger.info(f"  USE_SPARSE: {CONFIG.use_sparse}")
    logger.info(f"  EMBEDDING_MAX_LENGTH_DOC: {CONFIG.embedding_max_length_doc}")
    logger.info(f"  EMBEDDING_BATCH_SIZE: {CONFIG.embedding_batch_size}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
    from app.services.bge_embeddings import _get_optimal_backend_strategy
    optimal_backend = _get_optimal_backend_strategy()
    logger.info(f"  –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {optimal_backend}")

    try:
        stats = crawl_and_index(incremental=False)
        logger.success(f"‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        logger.success(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats['pages']} —Å—Ç—Ä–∞–Ω–∏—Ü, {stats['chunks']} —á–∞–Ω–∫–æ–≤")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
        raise
