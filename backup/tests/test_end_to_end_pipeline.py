#!/usr/bin/env python3
"""
End-to-end —Ç–µ—Å—Ç—ã pipeline –¥–ª—è –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤
"""

import pytest
import time
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent))

# Import data sources first to register them
from app.sources import edna_docs_source

from app.abstractions.data_source import plugin_manager
from app.services.indexing.optimized_pipeline import OptimizedPipeline, run_optimized_indexing
from app.services.indexing.metadata_aware_indexer import MetadataAwareIndexer
from ingestion.chunkers import chunk_text
from app.config import CONFIG


class TestEndToEndPipeline:
    """–¢–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ pipeline –æ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ –∑–∞–ø–∏—Å–∏ –≤ Qdrant"""

    @pytest.fixture(autouse=True)
    def setup_method(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞"""
        self.test_marker = f"test_run_{int(time.time())}"

    def test_single_document_extraction_and_chunking(self):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏ chunking –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        edna_config = {
            "base_url": "https://docs-chatcenter.edna.ru/",
            "strategy": "jina",
            "use_cache": False,
            "max_pages": 1
        }

        source = plugin_manager.get_source("edna_docs", edna_config)
        crawl_result = source.fetch_pages(max_pages=1)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑–≤–ª–µ—á–µ–Ω
        assert crawl_result.pages, "–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω"

        page = crawl_result.pages[0]
        assert len(page.content) > 0, "–ö–æ–Ω—Ç–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—É—Å—Ç–æ–π"
        assert page.title, "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—É—Å—Ç–æ–π"
        assert page.url, "URL –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—É—Å—Ç–æ–π"

        # –®–∞–≥ 2: Chunking
        chunks = chunk_text(page.content)
        assert len(chunks) > 0, "–ß–∞–Ω–∫–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
        total_chars = sum(len(chunk) for chunk in chunks)
        avg_chars = total_chars / len(chunks)

        # –ß–∞–Ω–∫–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –∏–ª–∏ –¥–ª–∏–Ω–Ω—ã–º–∏
        # –î–ª—è fallback chunker –¥–æ–ø—É—Å–∫–∞–µ–º –±–æ–ª—å—à–∏–π —Ä–∞–∑–º–µ—Ä
        assert 50 <= avg_chars <= 10000, f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —á–∞–Ω–∫–∞ {avg_chars} –Ω–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞"

    def test_adaptive_chunking_strategies(self):
        """–¢–µ—Å—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π chunking"""
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        edna_config = {
            "base_url": "https://docs-chatcenter.edna.ru/",
            "strategy": "jina",
            "use_cache": False,
            "max_pages": 1
        }

        source = plugin_manager.get_source("edna_docs", edna_config)
        crawl_result = source.fetch_pages(max_pages=1)

        if not crawl_result.pages or len(crawl_result.pages[0].content) == 0:
            pytest.skip("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º")

        page = crawl_result.pages[0]
        pipeline = OptimizedPipeline()

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π chunking
        adaptive_chunks = pipeline._adaptive_chunk_page(page)
        assert len(adaptive_chunks) > 0, "–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π chunking –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π chunking
        standard_chunks = pipeline._standard_chunk_page(page)
        assert len(standard_chunks) > 0, "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π chunking –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —á–∞–Ω–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è
        for chunk in adaptive_chunks[:2]:
            assert 'text' in chunk, "–ß–∞–Ω–∫ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç"
            assert 'payload' in chunk, "–ß–∞–Ω–∫ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç payload"
            assert 'url' in chunk['payload'], "Payload –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç URL"
            assert 'title' in chunk['payload'], "Payload –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫"

    @pytest.mark.slow
    def test_full_pipeline_indexing(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π (–º–µ–¥–ª–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç)"""
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π pipeline
        result = run_optimized_indexing(
            source_name="edna_docs",
            max_pages=2,  # –ù–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è —Ç–µ—Å—Ç–∞
            chunk_strategy="adaptive"
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
        assert result['success'], f"Pipeline –Ω–µ –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ: {result.get('error', 'Unknown error')}"
        assert result.get('pages', 0) > 0, "–ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"
        assert result.get('chunks', 0) > 0, "–ù–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞"
        assert result.get('duration', 0) > 0, "–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ"

    def test_metadata_aware_indexing(self):
        """–¢–µ—Å—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å enhanced metadata"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —á–∞–Ω–∫
        test_chunk = {
            "text": "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ enhanced metadata indexing. " * 10,
            "payload": {
                "url": "https://test.com/test",
                "title": "Test Document",
                "page_type": "guide",
                "source": "test",
                "language": "ru",
                "chunk_index": 0,
                "content_length": 500,
                "test_marker": self.test_marker
            }
        }

        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
        indexer = MetadataAwareIndexer()
        indexed_count = indexer.index_chunks_with_metadata([test_chunk])

        assert indexed_count == 1, "–ß–∞–Ω–∫ –Ω–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–∏—Å—å –≤ Qdrant
        from app.services.search.retrieval import client, COLLECTION

        # –ò—â–µ–º –ø–æ URL, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º
        search_result = client.scroll(
            collection_name=COLLECTION,
            scroll_filter={"must": [{"key": "url", "match": {"value": "https://test.com/test"}}]},
            limit=1,
            with_payload=True,
            with_vectors=False
        )

        found_chunks = search_result[0]
        assert len(found_chunks) == 1, f"–¢–µ—Å—Ç–æ–≤—ã–π —á–∞–Ω–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Qdrant. –ù–∞–π–¥–µ–Ω–æ: {len(found_chunks)}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º enhanced metadata
        payload = found_chunks[0].payload
        assert 'complexity_score' in payload, "Enhanced metadata –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ"
        assert 'semantic_density' in payload, "Semantic density –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ"
        assert 'boost_factor' in payload, "Boost factor –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ"

        # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        client.delete(
            collection_name=COLLECTION,
            points_selector=[str(found_chunks[0].id)]
        )

    def test_config_validation(self):
        """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω–∞
        assert CONFIG.chunk_min_tokens < CONFIG.chunk_max_tokens, "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ chunking"
        assert CONFIG.chunk_min_tokens > 0, "chunk_min_tokens –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º"
        assert CONFIG.chunk_max_tokens > 0, "chunk_max_tokens –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º"
        assert CONFIG.embedding_max_length_doc > 0, "embedding_max_length_doc –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º"
        assert CONFIG.crawler_strategy in ["jina", "http", "browser"], "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è crawler"

    def test_plugin_manager(self):
        """–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –ø–ª–∞–≥–∏–Ω–æ–≤"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã
        sources = plugin_manager.list_sources()
        assert "edna_docs" in sources, "–ò—Å—Ç–æ—á–Ω–∏–∫ edna_docs –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        edna_config = {
            "base_url": "https://docs-chatcenter.edna.ru/",
            "strategy": "jina",
            "use_cache": True
        }

        source = plugin_manager.get_source("edna_docs", edna_config)
        assert source is not None, "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ edna_docs"
        assert source.get_source_name() == "edna-docs", "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞"

    def test_chunking_quality_metrics(self):
        """–¢–µ—Å—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ chunking"""
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        edna_config = {
            "base_url": "https://docs-chatcenter.edna.ru/",
            "strategy": "jina",
            "use_cache": False,
            "max_pages": 1
        }

        source = plugin_manager.get_source("edna_docs", edna_config)
        crawl_result = source.fetch_pages(max_pages=1)

        if not crawl_result.pages or len(crawl_result.pages[0].content) == 0:
            pytest.skip("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º")

        page = crawl_result.pages[0]
        chunks = chunk_text(page.content)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        assert len(chunks) > 0, "–ù–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —á–∞–Ω–∫–æ–≤"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —á–∞–Ω–∫–∏ –Ω–µ –ø—É—Å—Ç—ã–µ
        for chunk in chunks:
            assert len(chunk.strip()) > 0, "–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—É—Å—Ç–æ–π —á–∞–Ω–∫"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—â–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞
        original_length = len(page.content)
        chunked_length = sum(len(chunk) for chunk in chunks)

        # –î–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–µ—Ä—é –∏–∑-–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (HTML –ø–∞—Ä—Å–∏–Ω–≥ –º–æ–∂–µ—Ç —Ç–µ—Ä—è—Ç—å –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
        assert chunked_length >= original_length * 0.25, f"–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –ø–æ—Ç–µ—Ä—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ chunking: {chunked_length} < {original_length * 0.25}"

    @pytest.mark.integration
    def test_connection_pool(self):
        """–¢–µ—Å—Ç connection pooling"""
        from app.services.infrastructure.connection_pool import get_connection_pool, close_connection_pool

        # –ü–æ–ª—É—á–∞–µ–º pool
        pool = get_connection_pool()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = pool.get_stats()
        assert 'active_sessions' in stats, "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ pool –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç active_sessions"
        assert 'max_sessions' in stats, "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ pool –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç max_sessions"
        assert stats['max_sessions'] > 0, "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Å—Å–∏–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º"

        # –û—á–∏—â–∞–µ–º pool
        close_connection_pool()

    @pytest.mark.slow
    def test_optimized_pipeline_end_to_end(self):
        """–¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ pipeline end-to-end"""
        print("üöÄ –¢–ï–°–¢ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û PIPELINE END-TO-END")
        print("=" * 60)

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_optimized_indexing –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
            result = run_optimized_indexing(
                source_name="edna_docs",
                max_pages=2,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
                chunk_strategy="adaptive"
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            assert result["success"], f"–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {result.get('error', 'Unknown error')}"
            assert result["pages"] > 0, "–ù–µ –±—ã–ª–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"
            assert result["chunks"] > 0, "–ù–µ –±—ã–ª–æ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞"

            print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü: {result['pages']}")
            print(f"   –ß–∞–Ω–∫–æ–≤: {result['chunks']}")
            print(f"   –í—Ä–µ–º—è: {result.get('duration', 'N/A')}s")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º pipeline: {e}")
            raise

    def test_chunking_quality_analysis(self):
        """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ chunking"""
        print("üîç –¢–ï–°–¢ –ê–ù–ê–õ–ò–ó–ê –ö–ê–ß–ï–°–¢–í–ê CHUNKING")
        print("=" * 60)

        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            edna_config = {
                "base_url": "https://docs-chatcenter.edna.ru/",
                "strategy": "jina",
                "use_cache": False,
                "max_pages": 1
            }

            source = plugin_manager.get_source("edna_docs", edna_config)
            crawl_result = source.fetch_pages(max_pages=1)

            assert crawl_result.pages, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"

            page = crawl_result.pages[0]
            print(f"üìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º chunking –¥–ª—è: {page.title}")
            print(f"   –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(page.content)} —Å–∏–º–≤–æ–ª–æ–≤")

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ chunking
            strategies = ["adaptive", "standard"]
            pipeline = OptimizedPipeline()

            for strategy in strategies:
                print(f"\nüîß –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy}")

                if strategy == "adaptive":
                    chunks = pipeline._adaptive_chunk_page(page)
                else:
                    chunks = pipeline._standard_chunk_page(page)

                print(f"   –ß–∞–Ω–∫–æ–≤: {len(chunks)}")

                if chunks:
                    total_chars = sum(len(chunk['text']) for chunk in chunks)
                    avg_chars = total_chars / len(chunks)

                    print(f"   –û–±—â–∞—è –¥–ª–∏–Ω–∞: {total_chars} —Å–∏–º–≤–æ–ª–æ–≤")
                    print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —á–∞–Ω–∫–∞: {avg_chars:.0f} —Å–∏–º–≤–æ–ª–æ–≤")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ chunking
                    assert len(chunks) > 0, f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {strategy} –Ω–µ —Å–æ–∑–¥–∞–ª–∞ —á–∞–Ω–∫–æ–≤"
                    assert avg_chars > 50, f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy}"
                    assert avg_chars < 2000, f"–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy}"

                    print(f"   ‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ chunking: OK")
                else:
                    print(f"   ‚ùå –°—Ç—Ä–∞—Ç–µ–≥–∏—è {strategy} –Ω–µ —Å–æ–∑–¥–∞–ª–∞ —á–∞–Ω–∫–æ–≤")

            print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ chunking –∑–∞–≤–µ—Ä—à–µ–Ω")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –∫–∞—á–µ—Å—Ç–≤–∞ chunking: {e}")
            raise


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pytest
def pytest_configure(config):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pytest"""
    config.addinivalue_line(
        "markers", "slow: marks tests as slow (deselect with '-m \"not slow\"')"
    )
    config.addinivalue_line(
        "markers", "integration: marks tests as integration tests"
    )


def pytest_collection_modifyitems(config, items):
    """–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–∞—Ä–∫–µ—Ä–æ–≤"""
    for item in items:
        # –ü–æ–º–µ—á–∞–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        if "full_pipeline" in item.name or "indexing" in item.name:
            item.add_marker(pytest.mark.slow)

        # –ü–æ–º–µ—á–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
        if "connection_pool" in item.name or "metadata_aware" in item.name:
            item.add_marker(pytest.mark.integration)
