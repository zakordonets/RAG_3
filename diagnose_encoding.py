#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏
"""
import sys
import os
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def check_text_encoding(text: str, source: str = "unknown"):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ç–µ–∫—Å—Ç–∞"""
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        encodings = ['utf-8', 'utf-8-sig', 'cp1251', 'iso-8859-1', 'windows-1252']

        for encoding in encodings:
            try:
                encoded = text.encode(encoding)
                decoded = encoded.decode(encoding)
                if decoded == text:
                    logger.success(f"‚úÖ {source}: –¢–µ–∫—Å—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤ {encoding}")
                    return encoding
            except (UnicodeEncodeError, UnicodeDecodeError):
                continue

        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        try:
            text.encode('utf-8')
            logger.info(f"‚úÖ {source}: –¢–µ–∫—Å—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤ UTF-8")
        except UnicodeEncodeError as e:
            logger.warning(f"‚ö†Ô∏è  {source}: –ü—Ä–æ–±–ª–µ–º—ã —Å UTF-8: {e}")

        return None

    except Exception as e:
        logger.error(f"‚ùå {source}: –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}")
        return None

def find_problematic_texts():
    """–ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –≤ –∫–µ—à–µ"""
    logger.info("üîç –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –≤ –∫–µ—à–µ...")

    try:
        from ingestion.crawl_cache import CrawlCache

        cache = CrawlCache()
        problematic_pages = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ –∫–µ—à–∞
        for i, (url, page_data) in enumerate(list(cache.pages.items())[:10]):
            try:
                content = page_data.get('content', '')
                if content:
                    encoding = check_text_encoding(content, f"URL {i+1}")
                    if not encoding:
                        problematic_pages.append({
                            'url': url,
                            'content_preview': content[:200],
                            'content_length': len(content)
                        })
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL {url}: {e}")

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(problematic_pages)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")
        return problematic_pages

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–µ—à—É: {e}")
        return []

def test_encoding_fixes():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–æ–∫"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∫–æ–¥–∏—Ä–æ–≤–æ–∫...")

    # –¢–µ—Å—Ç–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–±–ª–µ–º–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
    test_strings = [
        "–û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç",
        "–¢–µ–∫—Å—Ç —Å —Å–∏–º–≤–æ–ª–∞–º–∏: ¬©¬Æ‚Ñ¢‚Ç¨¬£¬•",
        "–¢–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫\n–∏ —Ç–∞–±—É–ª—è—Ü–∏—è–º–∏\t",
        "–¢–µ–∫—Å—Ç —Å –Ω–µ–æ–±—ã—á–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏: √±√°√©√≠√≥√∫",
        "–¢–µ–∫—Å—Ç —Å —ç–º–æ–¥–∑–∏: üòÄüéâüöÄ",
        "–¢–µ–∫—Å—Ç —Å HTML: <p>–ü—Ä–∏–≤–µ—Ç</p>",
        "–¢–µ–∫—Å—Ç —Å URL: https://example.com/path?param=value",
    ]

    for i, test_text in enumerate(test_strings):
        encoding = check_text_encoding(test_text, f"–¢–µ—Å—Ç {i+1}")
        if encoding:
            logger.info(f"   –¢–µ—Å—Ç {i+1}: {encoding} - OK")
        else:
            logger.warning(f"   –¢–µ—Å—Ç {i+1}: –ü—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π")

def check_system_encoding():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
    logger.info("üñ•Ô∏è  –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–æ–¥–∏—Ä–æ–≤–∫–∏...")

    # Python –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    logger.info(f"sys.getdefaultencoding(): {sys.getdefaultencoding()}")
    logger.info(f"sys.stdout.encoding: {sys.stdout.encoding}")
    logger.info(f"sys.stderr.encoding: {sys.stderr.encoding}")

    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    encoding_vars = ['PYTHONIOENCODING', 'LC_ALL', 'LANG', 'LC_CTYPE']
    for var in encoding_vars:
        value = os.environ.get(var, '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ')
        logger.info(f"{var}: {value}")

    # Windows —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if os.name == 'nt':
        logger.info("Windows detected:")
        logger.info(f"  os.environ.get('PYTHONIOENCODING'): {os.environ.get('PYTHONIOENCODING', '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ')}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        import subprocess
        try:
            result = subprocess.run(['chcp'], capture_output=True, text=True, shell=True)
            logger.info(f"  –ö–æ–¥–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {result.stdout.strip()}")
        except:
            logger.warning("  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")

def suggest_encoding_fixes():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π"""
    logger.info("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Æ –ö–û–î–ò–†–û–í–û–ö:")

    logger.info("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    logger.info("   set PYTHONIOENCODING=utf-8")

    logger.info("2. –î–ª—è Windows PowerShell:")
    logger.info("   $env:PYTHONIOENCODING='utf-8'")

    logger.info("3. –î–æ–±–∞–≤—å—Ç–µ –≤ –Ω–∞—á–∞–ª–æ Python —Å–∫—Ä–∏–ø—Ç–æ–≤:")
    logger.info("   import os")
    logger.info("   os.environ['PYTHONIOENCODING'] = 'utf-8'")

    logger.info("4. –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
    logger.info("   text.encode('utf-8', errors='ignore').decode('utf-8')")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    logger.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú –° –ö–û–î–ò–†–û–í–ö–ê–ú–ò")

    check_system_encoding()
    test_encoding_fixes()
    problematic_pages = find_problematic_texts()

    if problematic_pages:
        logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(problematic_pages)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü:")
        for page in problematic_pages[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            logger.warning(f"   URL: {page['url']}")
            logger.warning(f"   –ü—Ä–µ–≤—å—é: {page['content_preview'][:100]}...")

    suggest_encoding_fixes()

if __name__ == "__main__":
    main()
