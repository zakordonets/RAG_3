# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö (v4.3.0)

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ–±—ä—è—Å–Ω—è–µ—Ç, –∫–∞–∫ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ RAG-—Å–∏—Å—Ç–µ–º—É edna Chat Center —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –µ–¥–∏–Ω–æ–π DAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.

## üéØ –û–±–∑–æ—Ä

–°–∏—Å—Ç–µ–º–∞ v4.3.0 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **–µ–¥–∏–Ω—É—é DAG (Directed Acyclic Graph) –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É** –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ª—é–±—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä.

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

### –ï–¥–∏–Ω—ã–π Pipeline DAG

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    –ï–î–ò–ù–´–ô PIPELINE DAG                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  üìÅ SOURCE ADAPTERS (ingestion/adapters/)                    ‚îÇ
‚îÇ  ‚îú‚îÄ DocusaurusAdapter - —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ Docusaurus         ‚îÇ
‚îÇ  ‚îú‚îÄ WebsiteAdapter - –≤–µ–±-—Å–∞–π—Ç—ã (HTTP/HTML)                  ‚îÇ
‚îÇ  ‚îî‚îÄ YourCustomAdapter - –≤–∞—à –∏—Å—Ç–æ—á–Ω–∏–∫                        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üîÑ UNIFIED DAG (ingestion/pipeline/dag.py)                  ‚îÇ
‚îÇ  Parse ‚Üí Normalize ‚Üí Chunk ‚Üí Embed ‚Üí Index                  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üìù NORMALIZERS (ingestion/normalizers/)                     ‚îÇ
‚îÇ  ‚îú‚îÄ DocusaurusNormalizer - –æ—á–∏—Å—Ç–∫–∞ Docusaurus –∫–æ–Ω—Ç–µ–Ω—Ç–∞      ‚îÇ
‚îÇ  ‚îú‚îÄ HtmlNormalizer - –æ—á–∏—Å—Ç–∫–∞ HTML                           ‚îÇ
‚îÇ  ‚îî‚îÄ BaseNormalizer - –±–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è                   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  üóÑÔ∏è QDRANT WRITER (ingestion/pipeline/indexers/)             ‚îÇ
‚îÇ  ‚îî‚îÄ QdrantWriter - –∑–∞–ø–∏—Å—å –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î                    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

1. **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤** (`app/config/sources_config.py`)
   - –†–µ–µ—Å—Ç—Ä –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
   - –¢–∏–ø—ã –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (SourceType enum)
   - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞

2. **Source Adapters** (`ingestion/adapters/`)
   - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
   - –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å `SourceAdapter`
   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è `RawDoc` –æ–±—ä–µ–∫—Ç–æ–≤

3. **Normalizers** (`ingestion/normalizers/`)
   - –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
   - –ü–ª–∞–≥–∏–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
   - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ `ParsedDoc`

4. **Pipeline Steps** (`ingestion/pipeline/`)
   - Parser - –ø–∞—Ä—Å–∏–Ω–≥ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
   - Chunker - —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
   - Embedder - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ (dense + sparse)
   - QdrantWriter - –∑–∞–ø–∏—Å—å –≤ Qdrant

5. **–ï–¥–∏–Ω—ã–π entrypoint** (`ingestion/run.py`)
   - –ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è –ª—é–±—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
   - CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
   - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–º

6. **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è** (`ingestion/config.yaml`)
   - YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
   - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞–Ω–∫–∏–Ω–≥–∞, embeddings
   - –ü—Ä–æ—Ñ–∏–ª–∏ (development, production, testing)

## üìã –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

### –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã

| –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ | Source Adapter | –ü—Ä–∏–º–µ—Ä |
|-----|----------|----------------|--------|
| **DOCS_SITE** | Docusaurus, MkDocs | `DocusaurusAdapter` | –õ–æ–∫–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è |
| **EXTERNAL** | –í–µ–±-—Å–∞–π—Ç—ã | `WebsiteAdapter` | https://docs.example.com |

### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã (–¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)

–í `app/config/sources_config.py` –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∏–ø—ã:

```python
class SourceType(Enum):
    DOCS_SITE = "docs_site"          # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∞–π—Ç
    API_DOCS = "api_docs"            # API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (Swagger, OpenAPI)
    BLOG = "blog"                    # –ë–ª–æ–≥ –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏
    FAQ = "faq"                      # FAQ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    EXTERNAL = "external"            # –í–Ω–µ—à–Ω–∏–π —Å–∞–π—Ç
    LOCAL_FOLDER = "local_folder"    # –õ–æ–∫–∞–ª—å–Ω–∞—è –ø–∞–ø–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    FILE_COLLECTION = "file_collection"  # –ö–æ–ª–ª–µ–∫—Ü–∏—è —Ñ–∞–π–ª–æ–≤
    GIT_REPOSITORY = "git_repository"    # Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    CONFLUENCE = "confluence"        # Confluence wiki
    NOTION = "notion"               # Notion workspace
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞

### –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–¥–∞–ø—Ç–µ—Ä–æ–≤

#### –î–ª—è Docusaurus –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

```bash
# –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π Docusaurus –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
python ingestion/run.py docusaurus \
    --docs-root /path/to/docs \
    --site-base-url "https://docs.example.com" \
    --site-docs-prefix "/docs" \
    --reindex-mode full
```

#### –î–ª—è –≤–µ–±-—Å–∞–π—Ç–æ–≤

```bash
# –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤–µ–±-—Å–∞–π—Ç–∞
python ingestion/run.py website \
    --seed-urls "https://example.com" "https://example.com/docs" \
    --base-url "https://example.com" \
    --max-depth 3 \
    --reindex-mode full
```

### –°–ø–æ—Å–æ–± 2: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ sources_config.py

–î–æ–±–∞–≤—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤ `app/config/sources_config.py`:

```python
# –í –º–µ—Ç–æ–¥–µ _load_default_sources()
self.register(SourceConfig(
    name="my_docs",
    base_url="https://docs.example.com/",
    source_type=SourceType.DOCS_SITE,
    strategy="jina",
    use_cache=True,
    sitemap_path="/sitemap.xml",
    seed_urls=[
        "https://docs.example.com/",
        "https://docs.example.com/docs/",
    ],
    crawl_deny_prefixes=[
        "https://docs.example.com/api/",
        "https://docs.example.com/admin/",
    ],
    metadata_patterns={
        r'/docs/': {'section': 'docs', 'user_role': 'all'},
        r'/api/': {'section': 'api', 'user_role': 'developer'},
        r'/blog/': {'section': 'blog', 'user_role': 'all'},
    },
    timeout_s=30,
    crawl_delay_ms=1000,
    user_agent="RAGBot/1.0",
))
```

### –°–ø–æ—Å–æ–± 3: YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–î–æ–±–∞–≤—å—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ `ingestion/config.yaml`:

```yaml
sources:
  my_custom_source:
    enabled: true
    type: "website"
    base_url: "https://example.com"
    seed_urls:
      - "https://example.com/"
      - "https://example.com/docs/"

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞–Ω–∫–∏–Ω–≥–∞
    chunk:
      max_tokens: 300
      min_tokens: 150
      overlap_base: 50

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    indexing:
      upsert: true
      delete_missing: false
```

## üõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ Source Adapter

–ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞–¥–∞–ø—Ç–µ—Ä—ã –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç, —Å–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π.

### –®–∞–≥ 1: –°–æ–∑–¥–∞–π—Ç–µ –∫–ª–∞—Å—Å –∞–¥–∞–ø—Ç–µ—Ä–∞

```python
# ingestion/adapters/my_source.py
from typing import Iterable, Optional
from pathlib import Path
from loguru import logger

from ingestion.adapters.base import SourceAdapter, RawDoc

class MySourceAdapter(SourceAdapter):
    """
    –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –≤–∞—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö.

    –ü—Ä–∏–º–µ—Ä: API, –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –≤–Ω–µ—à–Ω–∏–π —Å–µ—Ä–≤–∏—Å –∏ —Ç.–¥.
    """

    def __init__(
        self,
        api_url: str,
        api_key: Optional[str] = None,
        max_pages: Optional[int] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥–∞–ø—Ç–µ—Ä–∞.

        Args:
            api_url: URL API
            api_key: API –∫–ª—é—á –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
        """
        self.api_url = api_url
        self.api_key = api_key
        self.max_pages = max_pages

    def iter_documents(self) -> Iterable[RawDoc]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.

        Yields:
            RawDoc: –°—ã—Ä–æ–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {self.api_url}")

        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        documents = self._fetch_documents()

        count = 0
        for doc in documents:
            if self.max_pages and count >= self.max_pages:
                logger.info(f"‚úã –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç: {self.max_pages} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                break

            # –°–æ–∑–¥–∞–µ–º RawDoc –æ–±—ä–µ–∫—Ç
            yield RawDoc(
                url=doc['url'],
                title=doc.get('title', ''),
                content=doc['content'],
                metadata={
                    'source': 'my_source',
                    'author': doc.get('author'),
                    'updated_at': doc.get('updated_at'),
                    # –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                }
            )

            count += 1

        logger.success(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    def _fetch_documents(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –≤–∞—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞: HTTP –∑–∞–ø—Ä–æ—Å—ã, —á—Ç–µ–Ω–∏–µ –ë–î –∏ —Ç.–¥.
        import requests

        headers = {}
        if self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'

        response = requests.get(
            f"{self.api_url}/documents",
            headers=headers
        )
        response.raise_for_status()

        return response.json()['documents']
```

### –®–∞–≥ 2: –°–æ–∑–¥–∞–π—Ç–µ Normalizer (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–ï—Å–ª–∏ –≤–∞—à –∏—Å—Ç–æ—á–Ω–∏–∫ —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:

```python
# ingestion/normalizers/my_source.py
import re
from ingestion.normalizers.base import BaseNormalizer
from ingestion.adapters.base import ParsedDoc

class MySourceNormalizer(BaseNormalizer):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤–∞—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""

    def get_step_name(self) -> str:
        return "MySourceNormalizer"

    def process(self, docs):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        for doc in docs:
            if not isinstance(doc, ParsedDoc):
                yield doc
                continue

            # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
            cleaned_content = self._clean_content(doc.content)

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å –æ—á–∏—â–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
            yield ParsedDoc(
                url=doc.url,
                title=doc.title,
                content=cleaned_content,
                metadata=doc.metadata
            )

    def _clean_content(self, content: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç"""
        # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        content = re.sub(r'\[SPECIAL_MARKER\]', '', content)

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        content = re.sub(r'\s+', ' ', content).strip()

        return content
```

### –®–∞–≥ 3: –°–æ–∑–¥–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é DAG

–î–æ–±–∞–≤—å—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è DAG –≤ `ingestion/run.py`:

```python
def create_my_source_dag(config: Dict[str, Any]) -> PipelineDAG:
    """–°–æ–∑–¥–∞–µ—Ç DAG –¥–ª—è –≤–∞—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
    steps = [
        Parser(),
        MySourceNormalizer(),  # –í–∞—à –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        BaseNormalizer(),       # –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        UnifiedChunkerStep(
            max_tokens=config.get("chunk_max_tokens", 300),
            min_tokens=config.get("chunk_min_tokens", 150),
            overlap_base=config.get("chunk_overlap_base", 50),
        ),
        Embedder(batch_size=config.get("batch_size", 16)),
        QdrantWriter(collection_name=config.get("collection_name", CONFIG.qdrant_collection))
    ]

    return PipelineDAG(steps)
```

### –®–∞–≥ 4: –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≤ run.py

–î–æ–±–∞–≤—å—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ—É–Ω–∫—Ü–∏—é `run_unified_indexing()`:

```python
def run_unified_indexing(
    source_type: str,
    config: Dict[str, Any],
    reindex_mode: str = "changed",
    clear_collection: bool = False
) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""

    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...

    try:
        # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        if source_type == "docusaurus":
            adapter = DocusaurusAdapter(...)
            dag = create_docusaurus_dag(config)

        elif source_type == "website":
            adapter = WebsiteAdapter(...)
            dag = create_website_dag(config)

        elif source_type == "my_source":  # –í–ê–® –ò–°–¢–û–ß–ù–ò–ö
            adapter = MySourceAdapter(
                api_url=config["api_url"],
                api_key=config.get("api_key"),
                max_pages=config.get("max_pages")
            )
            dag = create_my_source_dag(config)

        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source_type}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        documents = adapter.iter_documents()
        stats = dag.run(documents)

        return stats
```

### –®–∞–≥ 5: –î–æ–±–∞–≤—å—Ç–µ CLI –∫–æ–º–∞–Ω–¥—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–î–æ–±–∞–≤—å—Ç–µ –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –≤ `ingestion/run.py`:

```python
# –í —Ñ—É–Ω–∫—Ü–∏–∏ main()
elif args.source == "my_source":
    config = {
        "api_url": args.api_url,
        "api_key": args.api_key,
        "max_pages": args.max_pages,
        "chunk_max_tokens": args.chunk_max_tokens or CONFIG.chunk_max_tokens,
        "chunk_min_tokens": args.chunk_min_tokens or CONFIG.chunk_min_tokens,
        "collection_name": CONFIG.qdrant_collection,
    }

    stats = run_unified_indexing(
        source_type="my_source",
        config=config,
        reindex_mode=args.reindex_mode,
        clear_collection=args.clear_collection
    )

# –î–æ–±–∞–≤—å—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –ø–∞—Ä—Å–µ—Ä–∞
my_source_parser = subparsers.add_parser("my_source", help="–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑ –≤–∞—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞")
my_source_parser.add_argument("--api-url", required=True, help="URL API")
my_source_parser.add_argument("--api-key", help="API –∫–ª—é—á")
my_source_parser.add_argument("--max-pages", type=int, help="–ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–∞–Ω–∏—Ü")
```

## üìù –ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∞–π—Ç (Docusaurus)

```python
SourceConfig(
    name="docusaurus_docs",
    base_url="https://docs.example.com/",
    source_type=SourceType.DOCS_SITE,
    strategy="jina",
    use_cache=True,
    sitemap_path="/sitemap.xml",
    metadata_patterns={
        r'/docs/guide/': {'section': 'guide', 'page_type': 'guide'},
        r'/docs/api/': {'section': 'api', 'page_type': 'api'},
        r'/docs/faq/': {'section': 'faq', 'page_type': 'faq'},
    }
)
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
python ingestion/run.py docusaurus \
    --docs-root /path/to/docusaurus/docs \
    --site-base-url "https://docs.example.com" \
    --reindex-mode full
```

### –í–Ω–µ—à–Ω–∏–π –≤–µ–±-—Å–∞–π—Ç

```python
SourceConfig(
    name="external_site",
    base_url="https://example.com/",
    source_type=SourceType.EXTERNAL,
    strategy="jina",
    use_cache=True,
    seed_urls=[
        "https://example.com/",
        "https://example.com/blog/",
    ],
    crawl_deny_prefixes=[
        "https://example.com/admin/",
        "https://example.com/api/",
    ],
    metadata_patterns={
        r'/blog/': {'section': 'blog', 'page_type': 'blog'},
    }
)
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
python ingestion/run.py website \
    --seed-urls "https://example.com" \
    --base-url "https://example.com" \
    --max-depth 2 \
    --reindex-mode full
```

### API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

```python
SourceConfig(
    name="swagger_api",
    base_url="https://api.example.com/docs/",
    source_type=SourceType.API_DOCS,
    strategy="http",
    use_cache=True,
    custom_headers={
        "Authorization": "Bearer YOUR_TOKEN",
    },
    metadata_patterns={
        r'/docs/': {'section': 'api', 'user_role': 'developer', 'page_type': 'api'},
    }
)
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### Unit —Ç–µ—Å—Ç—ã

```python
# tests/test_my_source_adapter.py
import pytest
from ingestion.adapters.my_source import MySourceAdapter
from ingestion.adapters.base import RawDoc

def test_my_source_adapter_init():
    """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞"""
    adapter = MySourceAdapter(
        api_url="https://api.example.com",
        api_key="test_key",
        max_pages=10
    )

    assert adapter.api_url == "https://api.example.com"
    assert adapter.api_key == "test_key"
    assert adapter.max_pages == 10

def test_my_source_adapter_iter_documents(mocker):
    """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    # Mock –≤–Ω–µ—à–Ω–∏–π API
    mock_fetch = mocker.patch.object(
        MySourceAdapter,
        '_fetch_documents',
        return_value=[
            {
                'url': 'https://example.com/doc1',
                'title': 'Document 1',
                'content': 'Content 1',
            },
            {
                'url': 'https://example.com/doc2',
                'title': 'Document 2',
                'content': 'Content 2',
            }
        ]
    )

    adapter = MySourceAdapter(api_url="https://api.example.com")
    documents = list(adapter.iter_documents())

    assert len(documents) == 2
    assert all(isinstance(doc, RawDoc) for doc in documents)
    assert documents[0].url == 'https://example.com/doc1'
    assert documents[0].title == 'Document 1'
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã

```python
# tests/test_my_source_integration.py
import pytest
from ingestion.adapters.my_source import MySourceAdapter
from ingestion.pipeline.dag import PipelineDAG
from ingestion.run import create_my_source_dag

@pytest.mark.integration
def test_full_pipeline_my_source():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = {
        "api_url": "https://api.example.com",
        "chunk_max_tokens": 200,
        "chunk_min_tokens": 100,
        "collection_name": "test_collection",
    }

    # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –∏ DAG
    adapter = MySourceAdapter(
        api_url=config["api_url"],
        max_pages=5  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
    )
    dag = create_my_source_dag(config)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    documents = adapter.iter_documents()
    stats = dag.run(documents)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    assert stats["total_docs"] > 0
    assert stats["processed_docs"] > 0
    assert stats["failed_docs"] == 0
```

### –¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç

```python
#!/usr/bin/env python3
"""–¢–µ—Å—Ç –Ω–æ–≤–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from ingestion.adapters.my_source import MySourceAdapter
from loguru import logger

def test_adapter():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–¥–∞–ø—Ç–µ—Ä"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MySourceAdapter...")

    # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
    adapter = MySourceAdapter(
        api_url="https://api.example.com",
        api_key="your_api_key",
        max_pages=5
    )

    # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    documents = list(adapter.iter_documents())

    logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")

    # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 3 –¥–æ–∫—É–º–µ–Ω—Ç–∞
    for i, doc in enumerate(documents[:3], 1):
        logger.info(f"\nüìÑ –î–æ–∫—É–º–µ–Ω—Ç {i}:")
        logger.info(f"  URL: {doc.url}")
        logger.info(f"  Title: {doc.title}")
        logger.info(f"  Content length: {len(doc.content)} chars")
        logger.info(f"  Metadata: {doc.metadata}")

if __name__ == "__main__":
    test_adapter()
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ—Ç–ª–∞–¥–∫–∞

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:

```python
# –í–∫–ª—é—á–∏—Ç–µ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
import logging
from loguru import logger

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å DEBUG
logger.add("debug.log", level="DEBUG")
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

```bash
# –ó–∞–ø—É—Å–∫ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
python ingestion/run.py my_source \
    --api-url "https://api.example.com" \
    --max-pages 10 \
    --reindex-mode full

# –í—ã–≤–æ–¥:
# üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...
# üìÑ –ù–∞–π–¥–µ–Ω–æ 10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
# üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 5/10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (50.0%)
# üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 10/10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (100.0%)
# ‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
```

### –ú–µ—Ç—Ä–∏–∫–∏

–ü–æ—Å–ª–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –º–µ—Ç—Ä–∏–∫–∏:

```python
stats = run_unified_indexing(...)

print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['total_docs']}")
print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_docs']}")
print(f"–û—à–∏–±–æ–∫: {stats['failed_docs']}")
print(f"–í—Ä–µ–º—è: {stats.get('duration', 'N/A')}s")
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ Qdrant

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
curl http://localhost:6333/collections/chatcenter_docs

# –ü–æ–∏—Å–∫ –ø–æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
curl -X POST http://localhost:6333/collections/chatcenter_docs/points/search \
  -H "Content-Type: application/json" \
  -d '{"vector": [...], "limit": 5}'
```

## üéØ –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

### 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```python
def iter_documents(self) -> Iterable[RawDoc]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        documents = self._fetch_documents()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        return

    for doc in documents:
        try:
            yield RawDoc(
                url=doc['url'],
                title=doc.get('title', ''),
                content=doc['content'],
                metadata=doc.get('metadata', {})
            )
        except KeyError as e:
            logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø–æ–ª—è: {e}")
            continue
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc.get('url')}: {e}")
            continue
```

### 2. –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import hashlib
import json
from pathlib import Path

class MySourceAdapter(SourceAdapter):
    def __init__(self, api_url: str, use_cache: bool = True):
        self.api_url = api_url
        self.use_cache = use_cache
        self.cache_dir = Path("cache/my_source")
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_cache_path(self, doc_id: str) -> Path:
        """–ü—É—Ç—å –∫ –∫–µ—à—É –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        cache_key = hashlib.md5(doc_id.encode()).hexdigest()
        return self.cache_dir / f"{cache_key}.json"

    def _fetch_documents(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_path = self.cache_dir / "documents.json"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if self.use_cache and cache_path.exists():
            logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫–µ—à–∞")
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        documents = self._fetch_from_api()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
        if self.use_cache:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(documents, f, ensure_ascii=False, indent=2)

        return documents
```

### 3. –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è

```python
def iter_documents(self) -> Iterable[RawDoc]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
    from ingestion.state.state_manager import get_state_manager

    state_manager = get_state_manager()

    for doc in self._fetch_documents():
        doc_id = doc['url']
        current_hash = hashlib.md5(doc['content'].encode()).hexdigest()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç
        if state_manager.is_document_changed(doc_id, current_hash):
            logger.info(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω: {doc_id}")
            yield RawDoc(...)
        else:
            logger.debug(f"‚è≠Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∏–∑–º–µ–Ω–µ–Ω: {doc_id}")
```

### 4. –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
def iter_documents(self) -> Iterable[RawDoc]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –±–∞—Ç—á–∞–º–∏"""
    batch_size = 10

    documents = self._fetch_documents()
    batch = []

    for doc in documents:
        batch.append(doc)

        if len(batch) >= batch_size:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
            for processed_doc in self._process_batch(batch):
                yield processed_doc
            batch = []

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è
    if batch:
        for processed_doc in self._process_batch(batch):
            yield processed_doc
```

### 5. Rate Limiting

```python
import time

class MySourceAdapter(SourceAdapter):
    def __init__(self, api_url: str, rate_limit_delay: float = 1.0):
        self.api_url = api_url
        self.rate_limit_delay = rate_limit_delay
        self.last_request_time = 0

    def _fetch_documents(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å rate limiting"""
        elapsed = time.time() - self.last_request_time
        if elapsed < self.rate_limit_delay:
            time.sleep(self.rate_limit_delay - elapsed)

        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å
        response = requests.get(self.api_url)
        self.last_request_time = time.time()

        return response.json()
```

## ‚ùì –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### 1. "No documents found"

**–ü—Ä–∏—á–∏–Ω–∞**: –ê–¥–∞–ø—Ç–µ—Ä –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã

**–†–µ—à–µ–Ω–∏–µ**:
```python
# –î–æ–±–∞–≤—å—Ç–µ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
def iter_documents(self):
    documents = self._fetch_documents()
    logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    for doc in documents:
        logger.debug(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {doc.get('url')}")
        yield RawDoc(...)
```

#### 2. "ImportError: cannot import name 'MySourceAdapter'"

**–ü—Ä–∏—á–∏–Ω–∞**: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∏–º–ø–æ—Ä—Ç–∞

**–†–µ—à–µ–Ω–∏–µ**:
```python
# –í ingestion/run.py
from ingestion.adapters.my_source import MySourceAdapter

# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ __init__.py —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ ingestion/adapters/
```

#### 3. "Qdrant connection error"

**–ü—Ä–∏—á–∏–Ω–∞**: Qdrant –Ω–µ –∑–∞–ø—É—â–µ–Ω –∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π URL

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Qdrant
curl http://localhost:6333/collections

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ Qdrant
docker-compose up -d qdrant
```

#### 4. "Memory error during indexing"

**–ü—Ä–∏—á–∏–Ω–∞**: –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
python ingestion/run.py my_source \
    --chunk-max-tokens 200 \  # –í–º–µ—Å—Ç–æ 600
    --batch-size 8 \          # –í–º–µ—Å—Ç–æ 16
    --max-pages 100           # –û–≥—Ä–∞–Ω–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [Architecture](architecture.md) - –û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
- [Development Guide](development_guide.md) - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
- [Quickstart](quickstart.md) - –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞

- `ingestion/adapters/docusaurus.py` - –ü—Ä–∏–º–µ—Ä –∞–¥–∞–ø—Ç–µ—Ä–∞ –¥–ª—è Docusaurus
- `ingestion/adapters/website.py` - –ü—Ä–∏–º–µ—Ä –∞–¥–∞–ø—Ç–µ—Ä–∞ –¥–ª—è –≤–µ–±-—Å–∞–π—Ç–æ–≤
- `ingestion/normalizers/docusaurus.py` - –ü—Ä–∏–º–µ—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
- `tests/test_unified_dag.py` - –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Å—Ç–æ–≤

### –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
python -c "from app.config.sources_config import sources_registry; print(sources_registry.list_all())"

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ
python -c "from app.config.sources_config import get_source_config; print(get_source_config('edna_docs'))"

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–∞
python -m pytest tests/test_my_source_adapter.py -v

# –ó–∞–ø—É—Å–∫ —Å –æ—Ç–ª–∞–¥–∫–æ–π
python -m pdb ingestion/run.py my_source --api-url "..."
```

## üéì –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–ï–¥–∏–Ω–∞—è DAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ v4.3.0 —É–ø—Ä–æ—â–∞–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö. –û—Å–Ω–æ–≤–Ω—ã–µ —à–∞–≥–∏:

1. **–°–æ–∑–¥–∞–π—Ç–µ Source Adapter** - –Ω–∞—Å–ª–µ–¥—É–π—Ç–µ –æ—Ç `SourceAdapter`
2. **–†–µ–∞–ª–∏–∑—É–π—Ç–µ iter_documents()** - –≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ `RawDoc` –æ–±—ä–µ–∫—Ç—ã
3. **–°–æ–∑–¥–∞–π—Ç–µ DAG —Ñ—É–Ω–∫—Ü–∏—é** - –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —à–∞–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
4. **–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≤ run.py** - –¥–æ–±–∞–≤—å—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ `run_unified_indexing()`
5. **–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ** - –Ω–∞–ø–∏—à–∏—Ç–µ unit –∏ integration —Ç–µ—Å—Ç—ã

–°–ª–µ–¥—É—è —ç—Ç–æ–º—É —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É, –≤—ã —Å–º–æ–∂–µ—Ç–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª—é–±—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤!

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: –û–∫—Ç—è–±—Ä—å 2025
**–í–µ—Ä—Å–∏—è**: v4.3.0
**–°—Ç–∞—Ç—É—Å**: ‚úÖ –ê–∫—Ç—É–∞–ª—å–Ω–æ
