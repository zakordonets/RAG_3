# ADR-002: Adaptive Chunking Strategy

## Статус
Принято

## Дата
2024-09-30

## Контекст

В рамках рефакторинга RAG системы возникла необходимость улучшить стратегию разбивки документов на чанки. Существующий подход с фиксированным размером чанков не учитывает:

1. **Разнообразие типов контента**: API документация, руководства, FAQ, release notes имеют разную структуру
2. **Оптимальные размеры для BGE-M3**: Рекомендуемый диапазон 512±20% токенов (410-614)
3. **Семантическую целостность**: Важно сохранять логические блоки контента
4. **Производительность**: Разные стратегии для разных размеров документов

## Решение

Реализован адаптивный чанкер с тремя стратегиями в зависимости от размера документа:

### 1. Короткие документы (< 300 токенов)
- **Стратегия**: `WHOLE_DOCUMENT`
- **Поведение**: Документ обрабатывается целиком
- **Метаданные**: `chunk_type: "short_document"`, `is_complete_document: true`

### 2. Средние документы (300-800 токенов)
- **Стратегия**: `SEMANTIC` + `SLIDING_WINDOW`
- **Поведение**: Структурная сегментация + скользящее окно
- **Параметры**: 512 токенов, overlap 100 токенов
- **Метаданные**: `chunk_type: "medium_document"`

### 3. Длинные документы (> 800 токенов)
- **Стратегия**: `HIERARCHICAL` + `SLIDING_WINDOW`
- **Поведение**: Разбивка по заголовкам (h1-h6) + скользящее окно
- **Параметры**: 800 токенов, overlap 160 токенов
- **Метаданные**: `chunk_type: "long_document"`, `section_title`, `section_index`

## Технические детали

### Архитектура
```
AdaptiveChunker
├── DocumentType (SHORT, MEDIUM, LONG)
├── ChunkingStrategy (WHOLE_DOCUMENT, SEMANTIC, HIERARCHICAL)
└── ChunkMetadata (chunk_type, adaptive_chunking, word_count, token_count)
```

### Интеграция
- **ContentProcessor**: Единая точка входа для обработки контента
- **UnifiedTokenizer**: Быстрый токенайзер с кэшированием
- **MetricsCollector**: Отслеживание метрик чанкинга
- **Qdrant**: Сохранение с метаданными `adaptive_chunking: true`

### Конфигурация
```python
# app/config.py
chunk_strategy: str = "adaptive"  # adaptive|simple
adaptive_chunk_min_words_short: int = 50
adaptive_chunk_max_words_short: int = 300
adaptive_chunk_size_medium: int = 512
adaptive_chunk_overlap_medium: int = 100
adaptive_chunk_size_long: int = 800
adaptive_chunk_overlap_long: int = 160
```

## Преимущества

1. **Оптимизация для BGE-M3**: 80%+ чанков в диапазоне 410-614 токенов
2. **Семантическая целостность**: Сохранение логических блоков контента
3. **Производительность**: Быстрая обработка коротких документов
4. **Гибкость**: Легко настраиваемые параметры
5. **Мониторинг**: Детальные метрики для анализа качества

## Риски и митигация

### Риски
1. **Сложность**: Больше кода для поддержки
2. **Производительность**: Дополнительные вычисления токенов
3. **Совместимость**: Изменение формата payload в Qdrant

### Митигация
1. **Тестирование**: Полное покрытие юнит и интеграционными тестами
2. **Кэширование**: UnifiedTokenizer с кэшем для быстрого подсчета токенов
3. **Миграция**: Обратная совместимость через `adaptive_chunking` флаг
4. **Мониторинг**: Метрики для отслеживания производительности

## Альтернативы

### 1. Фиксированный размер (текущий)
- **Плюсы**: Простота
- **Минусы**: Неоптимально для BGE-M3, потеря семантики

### 2. Только семантический чанкинг
- **Плюсы**: Семантическая целостность
- **Минусы**: Медленно, не учитывает размеры

### 3. Только иерархический чанкинг
- **Плюсы**: Структурная целостность
- **Минусы**: Не подходит для всех типов контента

## Метрики успеха

1. **Оптимальное соотношение**: >80% чанков в диапазоне 410-614 токенов
2. **Производительность**: <100ms на страницу для коротких документов
3. **Качество**: Улучшение релевантности поиска на 15%
4. **Стабильность**: <1% ошибок при чанкинге

## Реализация

### Этапы
1. ✅ Создание AdaptiveChunker
2. ✅ Интеграция с ContentProcessor
3. ✅ Унификация токенайзера
4. ✅ Обновление метрик
5. ✅ Тестирование
6. ✅ Миграция legacy кода

### Файлы
- `ingestion/adaptive_chunker.py` - Основная логика
- `ingestion/processors/content_processor.py` - Интеграция
- `app/tokenizer.py` - Унифицированный токенайзер
- `app/metrics.py` - Метрики чанкинга
- `tests/test_adaptive_chunker.py` - Тесты

## Заключение

Адаптивный чанкинг обеспечивает оптимальное качество разбивки документов для BGE-M3 эмбеддингов при сохранении семантической целостности. Решение масштабируемо, тестируемо и обеспечивает детальный мониторинг качества.

## Связанные ADR
- ADR-001: BGE-M3 Unified Embeddings
- ADR-003: Content Processing Architecture (планируется)
