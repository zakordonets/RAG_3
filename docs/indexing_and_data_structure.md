# Indexing & Data Structure Guide

–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Å–∏—Å—Ç–µ–º–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º –¥–∞–Ω–Ω—ã—Ö RAG-—Å–∏—Å—Ç–µ–º—ã.

**–í–µ—Ä—Å–∏—è**: 4.3.1
**–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è**: 9 –æ–∫—Ç—è–±—Ä—è 2024
**–°—Ç–∞—Ç—É—Å**: Production Ready

---

## üìñ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏)
- [Data Structures](#data-structures)
  - [Qdrant Schema](#qdrant-schema)
  - [Metadata Structure](#—Å–∏—Å—Ç–µ–º–∞-–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
- [Chunking System](#—Å–∏—Å—Ç–µ–º–∞-chunking)
- [Indexing Pipeline](#pipeline-–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏)
- [Performance](#–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏-–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
- [Management](#—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ-–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π)
- [Troubleshooting](#troubleshooting)

---

## –û–±–∑–æ—Ä

–°–∏—Å—Ç–µ–º–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —á–µ—Ä–µ–∑ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π DAG pipeline —Å:

- ‚úÖ **–ì–∏–±—Ä–∏–¥–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã** - Dense (BGE-M3 1024d) + Sparse (keyword matching)
- ‚úÖ **Rich metadata** - 20+ –ø–æ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞
- ‚úÖ **Adaptive chunking** - –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–æ–≤ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- ‚úÖ **Production-ready** - Batch processing, caching, monitoring

### –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –°—Ç–∞—Ç—É—Å |
|-----------|------------|--------|
| **Vector DB** | Qdrant 1.7+ | ‚úÖ Production |
| **Embeddings** | BGE-M3 (dense + sparse) | ‚úÖ Production |
| **Chunking** | Universal + Adaptive | ‚úÖ Production |
| **Pipeline** | DAG architecture | ‚úÖ Production |
| **Metadata** | Enhanced 20+ fields | ‚úÖ Production |

### –°–≤—è–∑–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- üì¶ [Adding Data Sources](adding_data_sources.md) - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
- üèóÔ∏è [Architecture](architecture.md) - –û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
- üîß [Technical Specification](technical_specification.md) - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è

---

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

### DAG Pipeline

```
Data Source (Docusaurus, Website)
    ‚Üì SourceAdapter.iter_documents()
RawDoc (uri, bytes, meta)
    ‚Üì Parser
ParsedDoc (text, url, title)
    ‚Üì Normalizer
Normalized Text
    ‚Üì UniversalChunker
Chunks (text + metadata)
    ‚Üì Embedder (BGE-M3)
Chunks + Vectors (dense + sparse)
    ‚Üì QdrantWriter
Qdrant Collection (indexed)
```

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ú–æ–¥—É–ª—å | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|-----------|--------|------------|
| **SourceAdapter** | `ingestion/adapters/` | –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ |
| **Normalizers** | `ingestion/normalizers/` | –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è |
| **UniversalChunker** | `ingestion/chunking/` | –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏ |
| **Embedder** | `ingestion/pipeline/embedder.py` | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ |
| **QdrantWriter** | `ingestion/pipeline/indexers/` | –ó–∞–ø–∏—Å—å –≤ Qdrant |
| **PipelineDAG** | `ingestion/pipeline/dag.py` | –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è |

**–ü–æ–¥—Ä–æ–±–Ω–µ–µ**: –°–º. [adding_data_sources.md](adding_data_sources.md) –¥–ª—è –¥–µ—Ç–∞–ª–µ–π DAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.

---

## Data Structures

### Qdrant Schema

#### Collection Configuration

```python
from qdrant_client.models import VectorParams, Distance, SparseVectorParams

collection_config = {
    "vectors_config": {
        # Dense vector (BGE-M3)
        "dense": VectorParams(
            size=1024,
            distance=Distance.COSINE
        )
    },
    # Sparse vectors (keyword matching)
    "sparse_vectors_config": {
        "sparse": SparseVectorParams()
    },
    # HNSW index configuration
    "hnsw_config": {
        "m": 16,                      # –°–≤—è–∑–µ–π –Ω–∞ —É–∑–µ–ª
        "ef_construct": 100,          # –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è
        "ef_search": 50,              # –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞
        "full_scan_threshold": 10000  # –ü–æ—Ä–æ–≥ –ø–æ–ª–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    }
}
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**:
- **m**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π (trade-off –ø–∞–º—è—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ)
- **ef_construct**: –ì–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–≤—ã—à–µ = –º–µ–¥–ª–µ–Ω–Ω–µ–µ build, –ª—É—á—à–µ recall)
- **ef_search**: –ì–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ (–≤—ã—à–µ = –º–µ–¥–ª–µ–Ω–Ω–µ–µ search, –ª—É—á—à–µ precision)

#### Point Structure

```python
# –¢–æ—á–∫–∞ –≤ Qdrant
{
    "id": "abc123-chunk-0",  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
    "vector": {
        "dense": [0.1, 0.2, ..., 0.9],  # 1024 float
        "sparse": {                      # –û—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä!
            "indices": [1, 42, 567],
            "values": [0.8, 0.6, 0.4]
        }
    },
    "payload": {
        # –°–º. Metadata Structure –Ω–∏–∂–µ
    }
}
```

**–ö—Ä–∏—Ç–∏—á–Ω–æ**: Sparse –≤–µ–∫—Ç–æ—Ä—ã –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ `sparse_vectors` parameter, –ù–ï –≤ `vector`!

---

---

## –°–∏—Å—Ç–µ–º–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

### Payload Structure

–ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, —Å–æ—Ö—Ä–∞–Ω—è–µ–º—ã—Ö –≤ Qdrant payload:

```python
payload = {
    # === –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ) ===
    "url": str,              # URL –¥–æ–∫—É–º–µ–Ω—Ç–∞
    "title": str,            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    "text": str,             # –¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞
    "page_type": str,        # guide | api | faq | release_notes
    "source": str,           # docs-site | api-docs | blog
    "language": str,         # ru | en

    # === –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ===
    "doc_id": str,           # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
    "chunk_id": str,         # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —á–∞–Ω–∫–∞
    "chunk_index": int,      # –ü–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä —á–∞–Ω–∫–∞
    "heading_path": List[str],  # –ò–µ—Ä–∞—Ä—Ö–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤

    # === –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ ===
    "token_count": int,      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
    "content_length": int,   # –î–ª–∏–Ω–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
    "complexity_score": float,  # 0.0-1.0
    "semantic_density": float,  # 0.0-1.0 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    # === –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ ===
    "boost_factor": float,   # 1.0-2.0 (–º–Ω–æ–∂–∏—Ç–µ–ª—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
    "search_priority": float,  # 0.0-1.0

    # === –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ ===
    "created_at": str,       # ISO 8601
    "updated_at": str,       # ISO 8601 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    "indexed_at": float      # Unix timestamp
}
```

### –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

#### –ò–∑ URL –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

```python
# URL ‚Üí metadata mapping
url_patterns = {
    r'/docs/start/':      {'section': 'start', 'page_type': 'guide'},
    r'/docs/agent/':      {'section': 'agent', 'page_type': 'guide'},
    r'/docs/supervisor/': {'section': 'supervisor', 'page_type': 'guide'},
    r'/docs/admin/':      {'section': 'admin', 'page_type': 'guide'},
    r'/docs/api/':        {'section': 'api', 'page_type': 'api'},
    r'/blog/':            {'section': 'changelog', 'page_type': 'release_notes'},
    r'/faq':              {'section': 'faq', 'page_type': 'faq'}
}
```

#### –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

**Complexity Score** (—Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞):
```python
def calculate_complexity(text: str) -> float:
    """0.0 (–ø—Ä–æ—Å—Ç–æ–π) ‚Üí 1.0 (—Å–ª–æ–∂–Ω—ã–π)"""
    avg_sentence_len = len(text.split()) / max(len(text.split('.')), 1)
    technical_terms = len(re.findall(r'\b[A-Z]{2,}\b', text))
    code_blocks = len(re.findall(r'```', text))

    complexity = (
        (avg_sentence_len / 20) * 0.4 +
        (technical_terms / 100) * 0.3 +
        (code_blocks / 10) * 0.3
    )
    return min(1.0, complexity)
```

**Boost Factor** (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤ –ø–æ–∏—Å–∫–µ):
```python
def calculate_boost(metadata: dict) -> float:
    """1.0 (–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π) ‚Üí 2.0 (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)"""
    boost = 1.0

    # –ü–æ —Ç–∏–ø—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if metadata["page_type"] == "faq":   boost *= 1.3
    if metadata["page_type"] == "guide": boost *= 1.2

    # –ü–æ —Å–µ–∫—Ü–∏–∏
    if "start" in metadata.get("section", ""): boost *= 1.4

    return round(boost, 2)
```

---

## –°–∏—Å—Ç–µ–º–∞ Chunking

### UniversalChunker

**–ú–æ–¥—É–ª—å**: `ingestion/chunking/universal_chunker.py`

```python
from ingestion.chunking.universal_chunker import UniversalChunker

chunker = UniversalChunker(
    max_tokens=300,            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–æ–≤
    min_tokens=150,            # –§–æ–∫—É—Å –Ω–∞ –æ–¥–Ω–æ–π —Ç–µ–º–µ
    overlap_base=50,           # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
    oversize_block_policy="split",  # –†–∞–∑–±–∏–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –±–ª–æ–∫–æ–≤
    oversize_block_limit=600   # –õ–∏–º–∏—Ç –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ split
)

# –ß–∞–Ω–∫–∏–Ω–≥
chunks = chunker.chunk(
    text="–¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞...",
    content_type="markdown",   # markdown | html | text
    metadata={"url": "...", "title": "..."}
)
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Chunking (Production)

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|----------|----------|-------------|
| `max_tokens` | **300** | –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö —Ç–µ–º |
| `min_tokens` | **150** | –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è |
| `overlap_base` | **50** | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ |
| `oversize_block_policy` | split | –†–∞–∑–±–∏–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö code/table –±–ª–æ–∫–æ–≤ |
| `oversize_block_limit` | 600 | –ú–∞–∫—Å–∏–º—É–º –ø–µ—Ä–µ–¥ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º split |

### –ü–æ—á–µ–º—É 150-300, –∞ –Ω–µ –±–æ–ª—å—à–µ?

**–ü—Ä–æ–±–ª–µ–º–∞ —Å –±–æ–ª—å—à–∏–º–∏ —á–∞–Ω–∫–∞–º–∏** (350-600 —Ç–æ–∫–µ–Ω–æ–≤):
- ‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–æ–≤ —Å–ª–∏–≤–∞–ª–∞—Å—å
- ‚ùå LLM –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- ‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞—Å—Ç–µ–π —á–∞–Ω–∫–∞

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –º–µ–Ω—å—à–∏—Ö —á–∞–Ω–∫–æ–≤** (150-300 —Ç–æ–∫–µ–Ω–æ–≤):
- ‚úÖ –û–¥–∏–Ω —á–∞–Ω–∫ = –æ–¥–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ç–µ–º–∞
- ‚úÖ –¢–æ—á–Ω—ã–µ, —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- ‚úÖ –õ—É—á—à–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å retrieval

**–°–º. –¥–µ—Ç–∞–ª–∏**: [ADR-002](adr-002-adaptive-chunking.md) - –ø–æ—á–µ–º—É –ø—Ä–∞–∫—Ç–∏–∫–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Ç–µ–æ—Ä–∏–∏

### –¢–∏–ø–∏—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –ø–æ —Ç–∏–ø–∞–º

| –¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ | –¢–∏–ø–∏—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä | –ü–æ—á–µ–º—É |
|--------------|-----------------|--------|
| **–ü–∞—Ä–∞–≥—Ä–∞—Ñ guide** | 150-250 —Ç–æ–∫–µ–Ω–æ–≤ | –û–¥–Ω–∞ –º—ã—Å–ª—å/–∫–æ–Ω—Ü–µ–ø—Ü–∏—è |
| **FAQ answer** | 100-200 —Ç–æ–∫–µ–Ω–æ–≤ | –ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç |
| **Code block** | 100-400 —Ç–æ–∫–µ–Ω–æ–≤ | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ |
| **API endpoint** | 200-350 —Ç–æ–∫–µ–Ω–æ–≤ | –û–ø–∏—Å–∞–Ω–∏–µ + –ø—Ä–∏–º–µ—Ä—ã |

### Quality Gates

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è:
- ‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 50 —Ç–æ–∫–µ–Ω–æ–≤ (discard smaller)
- ‚úÖ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –ø–æ content hash
- ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è: –ø—Ä–æ–≤–µ—Ä–∫–∞ metadata completeness
- ‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –ø—É—Å—Ç—ã—Ö –∏ –º—É—Å–æ—Ä–Ω—ã—Ö —á–∞–Ω–∫–æ–≤

---

## Pipeline –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

### Unified DAG Pipeline (v4.3+)

**–ú–æ–¥—É–ª—å**: `ingestion/run.py`

```python
from ingestion.run import run_unified_indexing

# –ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
result = run_unified_indexing(
    source_type="docusaurus",
    config={
        "collection_name": "edna_docs",
        "docs_root": "/path/to/docs",
        "chunk_max_tokens": 600,
        "chunk_min_tokens": 350
    }
)

print(f"Indexed {result['chunks_count']} chunks from {result['docs_count']} documents")
```

### Pipeline Steps

| –®–∞–≥ | –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –í—Ö–æ–¥ | –í—ã—Ö–æ–¥ |
|-----|-----------|------|-------|
| 1 | **SourceAdapter** | Config | RawDoc(uri, bytes, meta) |
| 2 | **Parser** | RawDoc | ParsedDoc(text, url, title) |
| 3 | **Normalizer** | ParsedDoc | Normalized ParsedDoc |
| 4 | **UniversalChunker** | ParsedDoc | List[Chunk] |
| 5 | **Embedder** | List[Chunk] | Chunks + Vectors |
| 6 | **QdrantWriter** | Chunks + Vectors | Indexed count |

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Embeddings

**–ú–æ–¥—É–ª—å**: `ingestion/pipeline/embedder.py`

```python
from ingestion.pipeline.embedder import Embedder

embedder = Embedder()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
chunks_with_embeddings = []
for chunk in chunks:
    # Dense embedding (BGE-M3)
    dense_vec = embedder.embed_dense(chunk.text)

    # Sparse embedding (BGE-M3 sparse)
    sparse_vec = embedder.embed_sparse(chunk.text)

    chunks_with_embeddings.append({
        "text": chunk.text,
        "dense_vector": dense_vec,     # List[float] 1024 dim
        "sparse_vector": sparse_vec,   # {"indices": [...], "values": [...]}
        "metadata": chunk.metadata
    })
```

**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**:
- Dense batch size: 16-32 texts
- Sparse batch size: 8-16 texts
- Total time: ~5-10 —Å–µ–∫ –Ω–∞ batch

### –ó–∞–ø–∏—Å—å –≤ Qdrant

**–ú–æ–¥—É–ª—å**: `ingestion/pipeline/indexers/qdrant_writer.py`

```python
from ingestion.pipeline.indexers.qdrant_writer import QdrantWriter

writer = QdrantWriter(collection_name="edna_docs")

# Batch upsert
result = writer.upsert_points(
    points=[
        {
            "id": chunk_id,
            "vector": {"dense": dense_vec},  # Named vector
            "sparse_vectors": {"sparse": sparse_vec},  # –û—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä!
            "payload": metadata
        }
        for chunk_id, dense_vec, sparse_vec, metadata in batch
    ]
)

print(f"Upserted {result.count} points")
```

**–í–∞–∂–Ω–æ**: Sparse –≤–µ–∫—Ç–æ—Ä—ã –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ `sparse_vectors` parameter!

---

## –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π

### CLI Commands

**–û—Å–Ω–æ–≤–Ω–æ–π entrypoint**: `ingestion/run.py`

```bash
# –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
python -m ingestion.run \
  --source-type docusaurus \
  --config ingestion/config.yaml \
  --reindex all

# –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ changed)
python -m ingestion.run \
  --source-type docusaurus \
  --config ingestion/config.yaml \
  --reindex changed

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)
python -m ingestion.run \
  --source-type docusaurus \
  --config ingestion/config.yaml \
  --max-pages 10
```

### –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant

```bash
# –°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ö–µ–º–æ–π
python scripts/init_qdrant.py

# –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å (—É–¥–∞–ª–∏—Ç—å + —Å–æ–∑–¥–∞—Ç—å)
python scripts/init_qdrant.py --recreate

# –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏
python scripts/clear_collection.py --collection edna_docs
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

**–§–∞–π–ª**: `ingestion/config.yaml`

```yaml
source_type: docusaurus

# Source configuration
source:
  docs_root: "C:/path/to/docs"
  base_url: "https://docs-chatcenter.edna.ru"

# Chunking parameters
chunking:
  max_tokens: 600
  min_tokens: 350
  overlap_base: 100
  oversize_block_policy: split
  oversize_block_limit: 1200

# Qdrant settings
qdrant:
  collection_name: edna_docs
  url: http://localhost:6333
  batch_size: 100

# Performance
performance:
  embedding_batch_size: 16
  max_workers: 4
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏**:
```python
from qdrant_client import QdrantClient

client = QdrantClient(url="http://localhost:6333")
info = client.get_collection("edna_docs")

print(f"Points: {info.points_count}")
print(f"Vectors: {info.config.params.vectors}")
print(f"Sparse: {info.config.params.sparse_vectors}")
```

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö**:
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ distribution –ø–æ page_type
python scripts/check_text_field.py

# –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
python scripts/check_file_indexed.py --url "https://docs..."

# Full-text search –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
python scripts/check_full_text.py --query "–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è"
```

---

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### Batch Processing

| –û–ø–µ—Ä–∞—Ü–∏—è | Batch Size | –í—Ä–µ–º—è | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è |
|----------|------------|-------|-------------|
| **Dense embeddings** | 16-32 | 5-10 —Å–µ–∫ | GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω |
| **Sparse embeddings** | 8-16 | 3-5 —Å–µ–∫ | CPU –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω |
| **Qdrant upsert** | 100-500 | 1-2 —Å–µ–∫ | Parallel requests |

### Caching Strategy

**Crawl Cache** (—Ñ–∞–π–ª–æ–≤–∞—è):
- –õ–æ–∫–∞—Ü–∏—è: `cache/crawl/`
- –§–æ—Ä–º–∞—Ç: JSON files
- Retention: –ù–µ –æ—á–∏—â–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- –†–∞–∑–º–µ—Ä: ~100KB –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É

```bash
# –ü—Ä–æ—Å–º–æ—Ç—Ä –∫—ç—à–∞
ls -lh cache/crawl/*.json

# –û—á–∏—Å—Ç–∫–∞
rm -rf cache/crawl/*
```

**Redis Cache** (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
- Embeddings cache (TTL: 24h)
- Search results cache (TTL: 1h)
- In-memory fallback –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏

### GPU Acceleration

| –¢–∏–ø GPU | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –£—Å–∫–æ—Ä–µ–Ω–∏–µ |
|---------|------------|-----------|
| **NVIDIA** | CUDA | 10-20x vs CPU |
| **AMD/Intel** | DirectML + ONNX | 5-10x vs CPU |
| **CPU** | Fallback | Baseline |

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞**:
```bash
# .env
EMBEDDING_DEVICE=cuda        # cuda | directml | cpu | auto
EMBEDDINGS_BACKEND=onnx      # onnx | bge | hybrid
```

### Adaptive Search Weights

–í–µ—Å–∞ dense/sparse –∞–¥–∞–ø—Ç–∏—Ä—É—é—Ç—Å—è –ø–æ–¥ —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞:

```python
# –î–ª—è API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç keyword matching
{"sparse_weight": 0.7, "dense_weight": 0.3}

# –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö guides - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç semantic
{"sparse_weight": 0.3, "dense_weight": 0.7}

# –î–ª—è FAQ - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥
{"sparse_weight": 0.5, "dense_weight": 0.5}
```

---

## Troubleshooting

### 1. "Sparse vectors error"

**–°–∏–º–ø—Ç–æ–º—ã**:
```python
ValueError: Cannot pass both vector and sparse_vectors
```

**–ü—Ä–∏—á–∏–Ω–∞**: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ sparse –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ Qdrant

**–†–µ—à–µ–Ω–∏–µ**:
```python
# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
point = {
    "vector": {
        "dense": dense_vec,
        "sparse": sparse_vec  # –û–®–ò–ë–ö–ê!
    }
}

# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ
point = {
    "vector": {"dense": dense_vec},
    "sparse_vectors": {"sparse": sparse_vec}  # –û—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
}
```

### 2. "Empty chunks"

**–°–∏–º–ø—Ç–æ–º—ã**: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ —á–∞–Ω–∫–∏

**–ü—Ä–∏—á–∏–Ω—ã**:
- –î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (< min_tokens)
- –ü–∞—Ä—Å–µ—Ä –Ω–µ –∏–∑–≤–ª–µ–∫ —Ç–µ–∫—Å—Ç
- –¢–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ whitespace

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ parsed —Ç–µ–∫—Å—Ç
python scripts/check_file_indexed.py --url "https://problem-doc-url"

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏
grep "–ø—Ä–æ–ø—É—â–µ–Ω\|skipped" logs/app.log
```

**–†–µ—à–µ–Ω–∏–µ**:
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ parser –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
- –£–º–µ–Ω—å—à–∏—Ç–µ `min_tokens` –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –î–æ–±–∞–≤—å—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π normalizer

### 3. "Embeddings generation timeout"

**–°–∏–º–ø—Ç–æ–º—ã**: Pipeline –∑–∞–≤–∏—Å–∞–µ—Ç –Ω–∞ embeddings

**–ü—Ä–∏—á–∏–Ω—ã**:
- –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π batch
- –ù–µ—Ç GPU, –º–µ–¥–ª–µ–Ω–Ω—ã–π CPU
- –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ batch size –≤ config.yaml
performance:
  embedding_batch_size: 8  # –±—ã–ª–æ 16

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ ONNX –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
EMBEDDINGS_BACKEND=onnx
EMBEDDING_DEVICE=directml  # –¥–ª—è AMD/Intel GPU
```

### 4. "Qdrant connection refused"

**–°–∏–º–ø—Ç–æ–º—ã**: –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Qdrant

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ Qdrant –∑–∞–ø—É—â–µ–Ω
curl http://localhost:6333/collections

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Docker
docker ps | grep qdrant

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ—Ä—Ç
netstat -an | grep 6333
```

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ Qdrant
docker run -d -p 6333:6333 qdrant/qdrant

# –ò–ª–∏ —á–µ—Ä–µ–∑ docker-compose
docker-compose up -d qdrant
```

### 5. "Duplicate points"

**–°–∏–º–ø—Ç–æ–º—ã**: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑

**–ü—Ä–∏—á–∏–Ω–∞**: ID –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –Ω–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ

**–†–µ—à–µ–Ω–∏–µ**:
```python
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
chunk_id = f"{doc_id}-chunk-{chunk_index}"

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ upsert –≤–º–µ—Å—Ç–æ insert
writer.upsert_points(...)  # –û–±–Ω–æ–≤–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
```

### –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ —Å–∫—Ä–∏–ø—Ç—ã

```bash
# –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
python scripts/deep_analysis.py

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ URL
python scripts/check_file_indexed.py --url "https://docs..."

# –ü—Ä–æ–≤–µ—Ä–∫–∞ full-text –ø–æ–∏—Å–∫–∞
python scripts/check_full_text.py --query "–≤–∞—à –∑–∞–ø—Ä–æ—Å"

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ retrieval
python scripts/test_retrieval_for_url.py --url "https://docs..."

# –í–∞–ª–∏–¥–∞—Ü–∏—è pipeline
pytest tests/test_unified_pipeline.py -v
```

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

**–£—Ä–æ–≤–Ω–∏ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏**:
```python
# DEBUG - –¥–µ—Ç–∞–ª–∏ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
logger.debug(f"Processing document: {url}")
logger.debug(f"Created {len(chunks)} chunks")

# INFO - –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
logger.info(f"Indexed {count} documents")

# WARNING - –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
logger.warning(f"Skipped {url}: {reason}")

# ERROR - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
logger.error(f"Failed to index {url}: {error}")
```

---

## üìö –°–≤—è–∑–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [Adding Data Sources](adding_data_sources.md) - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- [Architecture](architecture.md) - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
- [Technical Specification](technical_specification.md) - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è
- [Development Guide](development_guide.md) - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞

### –ü–æ–ª–µ–∑–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã

| –°–∫—Ä–∏–ø—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|--------|------------|
| `scripts/init_qdrant.py` | –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| `scripts/clear_collection.py` | –û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| `scripts/check_file_indexed.py` | –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ URL |
| `scripts/deep_analysis.py` | –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| `scripts/pipeline_text_flow.py` | –û—Ç–ª–∞–¥–∫–∞ pipeline |

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞**: 4.3.1
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 9 –æ–∫—Ç—è–±—Ä—è 2024
**–°—Ç–∞—Ç—É—Å**: Production Ready
### –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏ –∏–∑ _category_.json

–ö–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ group_labels –∏ groups_path, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç—Ä–∞–∂–∞—é—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É
doc—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–¥–µ—Ä–µ–≤–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π Docusaurus) –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è:

- **–ë—É—Å—Ç–∏–Ω–≥–∞** –≤ –ø–æ–∏—Å–∫–µ: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ê–†–ú –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞" –∏–ª–∏ "API"),
  —Å–∏—Å—Ç–µ–º–∞ –ø–æ–≤—ã—à–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –≤–µ—Ç–∫–∏.
- **–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤**: –≤ –æ—Ç–≤–µ—Ç–∞—Ö –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Å—Å—ã–ª–∫–∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–º —ç–ª–µ–º–µ–Ω—Ç–æ–º groups_path,
  —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –±—ã–ª–æ –æ—á–µ–≤–∏–¥–Ω–æ, –≤ –∫–∞–∫–æ–º —Ä–∞–∑–¥–µ–ª–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –¥–æ–∫—É–º–µ–Ω—Ç.

–ü—Ä–∏–º–µ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:

`
{
  "group_labels": ["API", "API edna Chat Center", "–¢—Ä–µ–¥—ã"],
  "groups_path": ["API", "API edna Chat Center", "–¢—Ä–µ–¥—ã"],
  "current_group": "–¢—Ä–µ–¥—ã"
}
`

–°–∏–Ω–æ–Ω–∏–º—ã –∏ –≤–µ—Å–∞ –¥–ª—è –±—É—Å—Ç–∏–Ω–≥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É—é—Ç—Å—è —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è GROUP_BOOST_SYNONYMS (JSON),
–ª–∏–±–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ê–†–ú –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞, –ê–†–ú –∞–≥–µ–Ω—Ç–∞, –ê–†–ú —Å—É–ø–µ—Ä–≤–∞–π–∑–µ—Ä–∞, API).
