# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (v3.0.0)

## üìã –û–±–∑–æ—Ä

–î–∞–Ω–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–º–æ–∂–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–π –∫–æ–¥ –∫ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ RAG-—Å–∏—Å—Ç–µ–º—ã –ø–æ—Å–ª–µ –∫—Ä—É–ø–Ω–æ–≥–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ v3.0.0.

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è

### 1. –ú–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ services/ (–≠—Ç–∞–ø—ã 1-5)

**–î–æ:**
```python
from app.services.embeddings import embed_dense
from app.services.bge_embeddings import embed_batch_optimized
from app.services.orchestrator import RAGOrchestrator
```

**–ü–æ—Å–ª–µ:**
```python
from app.services.core.embeddings import embed_dense, embed_batch_optimized
from app.services.infrastructure.orchestrator import RAGOrchestrator
```

### 2. UnifiedChunker (–≠—Ç–∞–ø 2)

**–î–æ:**
```python
from ingestion.chunkers.simple_chunker import chunk_text
from ingestion.chunkers.adaptive_chunker import adaptive_chunk_text
from ingestion.chunkers.semantic_chunker import SemanticChunker
```

**–ü–æ—Å–ª–µ:**
```python
from ingestion.chunkers import chunk_text, UnifiedChunker, ChunkingStrategy

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
chunker = UnifiedChunker()
chunks = chunker.chunk_text(text, ChunkingStrategy.AUTO)
```

### 3. GPU Manager (–≠—Ç–∞–ø 3)

**–î–æ:**
```python
from app.gpu_utils import get_device, optimize_for_gpu
from app.gpu_utils_windows import get_gpu_info
```

**–ü–æ—Å–ª–µ:**
```python
from app.hardware import get_device, optimize_for_gpu, get_gpu_info
```

### 4. –û–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ crawlers (–≠—Ç–∞–ø 5)

**–î–æ:**
```python
from ingestion.crawler import crawl_website
```

**–ü–æ—Å–ª–µ:**
```python
from ingestion.crawlers import CrawlerFactory, SourceConfig, SourceType

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
source_config = SourceConfig(
    name="edna_docs",
    source_type=SourceType.DOCS_SITE,
    base_url="https://docs-chatcenter.edna.ru/"
)
crawler = CrawlerFactory.create_crawler(source_config)
pages = crawler.crawl(max_pages=100)
```

### 5. TextProcessor (–≠—Ç–∞–ø 6)

**–î–æ:**
```python
from app.text_utils import clean_text_for_processing
from app.logging_config import clean_text_for_logging
```

**–ü–æ—Å–ª–µ:**
```python
from app.utils import clean_text_for_processing, clean_text_for_logging

# –ò–ª–∏ —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å
from app.utils import TextProcessor
processor = TextProcessor()
cleaned_text = processor.clean_text_for_processing(text)
```

### 6. MetadataExtractor (–≠—Ç–∞–ø 7)

**–î–æ:**
```python
from app.sources_registry import extract_url_metadata
# –†–∞–∑–±—Ä–æ—Å–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
```

**–ü–æ—Å–ª–µ:**
```python
from app.utils import extract_url_metadata, MetadataExtractor

# –ò–ª–∏ —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å
extractor = MetadataExtractor()
metadata = extractor.extract_comprehensive_metadata(content, url)
```

### 7. Telegram Adapters (–≠—Ç–∞–ø 8)

**–î–æ:**
```python
from adapters.rate_limiter import RateLimiter
from adapters.telegram_enhanced import TelegramBot
from adapters.telegram_polling import run_polling_loop
```

**–ü–æ—Å–ª–µ:**
```python
from adapters.telegram import RateLimiter, TelegramBot, run_polling_loop

# –ò–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
from adapters.telegram.bot import TelegramBot
from adapters.telegram.rate_limiter import RateLimiter
from adapters.telegram.polling import run_polling_loop
```

### 8. ContentLoader (–≠—Ç–∞–ø 9)

**–î–æ:**
```python
from ingestion.universal_loader import load_content_universal
```

**–ü–æ—Å–ª–µ:**
```python
from ingestion.content_loader import load_content_universal

# –ò–ª–∏ —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å
from ingestion.content_loader import ContentLoader
loader = ContentLoader()
result = loader.load_content(url, content)
```

### 9. –†–µ–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ app/ (–≠—Ç–∞–ø 10)

**–î–æ:**
```python
from app.caching import get_cache_stats
from app.metrics import get_metrics_collector
from app.security import security_monitor
from app.tokenizer import count_tokens
from app.validation import validate_query_data
```

**–ü–æ—Å–ª–µ:**
```python
# –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
from app.infrastructure import get_cache_stats, get_metrics_collector, security_monitor

# –£—Ç–∏–ª–∏—Ç—ã
from app.utils import count_tokens, validate_query_data

# –ò–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
from app.infrastructure.caching import get_cache_stats
from app.infrastructure.metrics import get_metrics_collector
from app.utils.tokenizer import count_tokens
from app.utils.validation import validate_query_data
```

## üîÑ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–≠—Ç–∞–ø—ã 6-10)

**–î–æ:**
```python
from ingestion.crawler import crawl, crawl_with_sitemap_progress
```

**–ü–æ—Å–ª–µ:**
```python
from ingestion.crawlers import CrawlerFactory
from app.sources_registry import SourceConfig, SourceType

# –°–æ–∑–¥–∞–Ω–∏–µ crawler
config = SourceConfig(
    name="edna_docs",
    source_type=SourceType.DOCS_SITE,
    base_url="https://docs-chatcenter.edna.ru/"
)
crawler = CrawlerFactory.create_crawler(config)
results = crawler.crawl(max_pages=10)
```

## üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏:

```bash
python scripts/check_compatibility.py
```

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤

–î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:

```bash
python scripts/migrate_imports.py
```

## üìù –†—É—á–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è

### 1. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ services/

–ù–∞–π–¥–∏—Ç–µ –∏ –∑–∞–º–µ–Ω–∏—Ç–µ –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã:

```python
# –°—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from app.services.embeddings import *
from app.services.bge_embeddings import *
from app.services.orchestrator import *
from app.services.retrieval import *
from app.services.rerank import *
from app.services.core.llm_router import *
from app.services.query_processing import *

# –ù–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from app.services.core.embeddings import *
from app.services.infrastructure.orchestrator import *
from app.services.search.retrieval import *
from app.services.search.rerank import *
from app.services.core.llm_router import *
from app.services.core.query_processing import *
```

### 2. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ chunkers

```python
# –°—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from ingestion.chunkers.simple_chunker import chunk_text, text_hash
from ingestion.chunkers.adaptive_chunker import adaptive_chunk_text
from ingestion.chunkers.semantic_chunker import SemanticChunker

# –ù–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from ingestion.chunkers import chunk_text, text_hash, UnifiedChunker, ChunkingStrategy
```

### 3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ GPU —É—Ç–∏–ª–∏—Ç

```python
# –°—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from app.gpu_utils import get_device, optimize_for_gpu
from app.gpu_utils_windows import get_gpu_info
from app.gpu_utils_windows_fallback import clear_gpu_cache

# –ù–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from app.hardware import get_device, optimize_for_gpu, get_gpu_info, clear_gpu_cache
```

### 4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ crawlers

```python
# –°—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from ingestion.crawler import crawl, crawl_with_sitemap_progress, crawl_mkdocs_index

# –ù–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from ingestion.crawlers import CrawlerFactory
from app.sources_registry import SourceConfig, SourceType

# –°–æ–∑–¥–∞–Ω–∏–µ crawler
config = SourceConfig(
    name="source_name",
    source_type=SourceType.DOCS_SITE,  # –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ç–∏–ø
    base_url="https://example.com/"
)
crawler = CrawlerFactory.create_crawler(config)
results = crawler.crawl(max_pages=10, strategy="jina")
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –í—Å–µ —Ç–µ—Å—Ç—ã
python -m pytest tests/ -v

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Å—Ç—ã
python -m pytest tests/test_adaptive_chunker.py -v
python -m pytest tests/test_crawlers.py -v
python -m pytest tests/test_end_to_end_pipeline.py -v
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

```python
# –¢–µ—Å—Ç UnifiedChunker
from ingestion.chunkers import UnifiedChunker, ChunkingStrategy
chunker = UnifiedChunker()
chunks = chunker.chunk_text("–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç", ChunkingStrategy.AUTO)
print(f"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")

# –¢–µ—Å—Ç GPU Manager
from app.hardware import get_device, get_gpu_info
device = get_device()
info = get_gpu_info()
print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}, –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {info}")

# –¢–µ—Å—Ç Crawler Factory
from ingestion.crawlers import CrawlerFactory
from app.sources_registry import SourceConfig, SourceType
config = SourceConfig(name="test", source_type=SourceType.DOCS_SITE, base_url="https://example.com/")
crawler = CrawlerFactory.create_crawler(config)
print(f"–°–æ–∑–¥–∞–Ω crawler: {type(crawler).__name__}")
```

## ‚ö†Ô∏è –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

### 1. –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º–ø–æ—Ä—Ç—ã

–ï—Å–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—à–∏–±–∫–∏ –∏–º–ø–æ—Ä—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:

```python
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏
from app.services.core.embeddings import embed_dense  # ‚úÖ
from app.services.embeddings import embed_dense       # ‚ùå
```

### 2. –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ API

–ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–≥—É—Ç –∏–º–µ—Ç—å –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã:

```python
# –°—Ç–∞—Ä—ã–π API
chunks = chunk_text(text, min_tokens=100, max_tokens=500)

# –ù–æ–≤—ã–π API
from ingestion.chunkers import UnifiedChunker, ChunkingStrategy
chunker = UnifiedChunker()
chunks = chunker.chunk_text(text, ChunkingStrategy.SIMPLE, min_tokens=100, max_tokens=500)
```

### 3. –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ç–∏–ø–∞—Ö

```python
# –°—Ç–∞—Ä—ã–π API - –≤–æ–∑–≤—Ä–∞—â–∞–ª dict
page_data = {"url": url, "html": html, "text": text}

# –ù–æ–≤—ã–π API - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç CrawlResult
from ingestion.crawlers import CrawlResult
result = CrawlResult(url=url, html=html, text=text, title="", metadata={})
```

## üîß –û—Ç–ª–∞–¥–∫–∞

### –í–∫–ª—é—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤

```python
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç
try:
    from app.services.core.embeddings import embed_dense
    print("‚úÖ embeddings –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ embeddings: {e}")
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

```python
# –¢–µ—Å—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
from ingestion.chunkers import chunk_text
from app.hardware import get_device
from ingestion.crawlers import CrawlerFactory

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç
chunks = chunk_text("–¢–µ—Å—Ç")
device = get_device()
print(f"Chunks: {len(chunks)}, Device: {device}")
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **–ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É**: [docs/refactoring_complete_report.md](refactoring_complete_report.md)
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: [docs/architecture.md](architecture.md)
- **–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞**: [docs/development_guide.md](development_guide.md)
- **CHANGELOG**: [CHANGELOG.md](../CHANGELOG.md)

## üÜò –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–º–æ—â–∏

–ï—Å–ª–∏ —É –≤–∞—Å –≤–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –º–∏–≥—Ä–∞—Ü–∏–µ–π:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É](refactoring_complete_report.md)
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –≤ [development_guide.md](development_guide.md)
4. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∫–æ–º–∞–Ω–¥–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-01-06
**–í–µ—Ä—Å–∏—è:** 1.0
**–°—Ç–∞—Ç—É—Å:** –ê–∫—Ç—É–∞–ª—å–Ω–æ ‚úÖ
