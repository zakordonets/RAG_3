#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ RAG —Å–∏—Å—Ç–µ–º–µ
"""
import sys
import os
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def setup_encoding():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É"""
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    os.environ['PYTHONUTF8'] = '1'

def test_search():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ –≤ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞...")

    try:
        from app.services.retrieval import hybrid_search
        from app.services.bge_embeddings import embed_unified

        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        test_queries = [
            "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≥–µ–Ω—Ç–∞?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ WebSocket?",
            "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è?",
            "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            "API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"
        ]

        logger.info(f"üìù –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(test_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤...")

        for i, query in enumerate(test_queries, 1):
            logger.info(f"\nüîç –ó–∞–ø—Ä–æ—Å {i}: '{query}'")

            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
                logger.info("  üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏...")
                query_embedding = embed_unified(
                    text=query,
                    max_length=512,
                    return_dense=True,
                    return_sparse=True,
                    context="query"
                )

                dense_vec = query_embedding.get('dense_vecs', [[]])[0]
                sparse_vec = query_embedding.get('lexical_weights', [{}])[0]

                logger.info(f"  ‚úÖ Dense –≤–µ–∫—Ç–æ—Ä: {len(dense_vec)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
                logger.info(f"  ‚úÖ Sparse –≤–µ–∫—Ç–æ—Ä: {len(sparse_vec)} —Ç–æ–∫–µ–Ω–æ–≤")

                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
                logger.info("  üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫...")
                results = hybrid_search(
                    query_dense=dense_vec,
                    query_sparse=sparse_vec,
                    k=5
                )

                if results:
                    logger.info(f"  üìã –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
                    for j, result in enumerate(results, 1):
                        score = result.get('score', 0)
                        payload = result.get('payload', {})
                        url = payload.get('url', 'N/A')
                        title = payload.get('title', 'N/A')
                        text_preview = payload.get('text', '')[:100] + '...' if payload.get('text') else 'N/A'

                        logger.info(f"    {j}. Score: {score:.3f}")
                        logger.info(f"       URL: {url}")
                        logger.info(f"       Title: {title}")
                        logger.info(f"       Text: {text_preview}")
                else:
                    logger.warning(f"  ‚ö†Ô∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")

            except Exception as e:
                logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ '{query}': {e}")

        logger.success("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        import traceback
        logger.error(traceback.format_exc())

def test_collection_info():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
    logger.info("üìä –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏...")

    try:
        from app.services.metadata_aware_indexer import MetadataAwareIndexer

        indexer = MetadataAwareIndexer()

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        info = indexer.client.get_collection('chatcenter_docs')

        logger.info(f"üìà –°—Ç–∞—Ç—É—Å –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {info.status}")
        logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫: {info.points_count}")
        logger.info(f"üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤: {info.config}")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–ê –í RAG –°–ò–°–¢–ï–ú–ï")

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
    setup_encoding()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
    test_collection_info()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    test_search()

if __name__ == "__main__":
    main()
