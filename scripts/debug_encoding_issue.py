#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""
import asyncio
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é app
sys.path.append(str(Path(__file__).parent.parent))

from app.services.retrieval import client, COLLECTION


class EncodingDebugger:
    """–û—Ç–ª–∞–¥—á–∏–∫ –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π"""

    def __init__(self):
        self.client = client
        self.collection = COLLECTION

    def check_raw_content(self, limit: int = 5) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            results = self.client.scroll(
                collection_name=self.collection,
                limit=limit,
                with_payload=True
            )

            docs = []
            for doc in results[0]:
                payload = doc.payload

                # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                raw_content = payload.get("content", "")
                raw_content_type = type(raw_content).__name__
                raw_content_repr = repr(raw_content)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
                encoding_info = self._analyze_encoding(raw_content)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–ª—è
                title = payload.get("title", "")
                url = payload.get("url", "")

                docs.append({
                    "id": str(doc.id),
                    "url": url,
                    "title": title,
                    "raw_content_type": raw_content_type,
                    "raw_content_length": len(str(raw_content)),
                    "raw_content_repr": raw_content_repr[:200] + "..." if len(raw_content_repr) > 200 else raw_content_repr,
                    "encoding_info": encoding_info,
                    "title_encoding": self._analyze_encoding(title),
                    "all_payload_keys": list(payload.keys())
                })

            return docs

        except Exception as e:
            return [{"error": str(e)}]

    def _analyze_encoding(self, text: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return {"is_empty": True}

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            encodings_to_try = ['utf-8', 'cp1251', 'iso-8859-1', 'windows-1252']
            encoding_results = {}

            for encoding in encodings_to_try:
                try:
                    if isinstance(text, bytes):
                        decoded = text.decode(encoding)
                        encoding_results[encoding] = {
                            "success": True,
                            "length": len(decoded),
                            "preview": decoded[:100] + "..." if len(decoded) > 100 else decoded
                        }
                    else:
                        # –¢–µ–∫—Å—Ç —É–∂–µ –≤ —Å—Ç—Ä–æ–∫–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–∂–Ω–æ –ª–∏ –µ–≥–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å/–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å
                        encoded = text.encode(encoding)
                        decoded = encoded.decode(encoding)
                        encoding_results[encoding] = {
                            "success": True,
                            "length": len(decoded),
                            "preview": decoded[:100] + "..." if len(decoded) > 100 else decoded
                        }
                except Exception as e:
                    encoding_results[encoding] = {
                        "success": False,
                        "error": str(e)
                    }

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            has_russian = any(ord(c) > 127 for c in str(text)[:200]) if text else False

            return {
                "is_empty": len(str(text).strip()) == 0,
                "has_russian": has_russian,
                "encodings": encoding_results,
                "raw_type": type(text).__name__,
                "raw_length": len(str(text))
            }

        except Exception as e:
            return {"error": str(e)}

    def test_jina_fetch(self, test_urls: List[str]) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ Jina Reader"""
        results = {}

        for url in test_urls:
            try:
                print(f"   üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º Jina Reader –¥–ª—è: {url}")

                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ URL
                import requests
                response = requests.get(url, timeout=10)

                results[url] = {
                    "http_success": response.status_code == 200,
                    "status_code": response.status_code,
                    "content_length": len(response.content),
                    "content_type": response.headers.get('content-type', 'unknown'),
                    "encoding": response.encoding,
                    "preview": response.text[:200] + "..." if len(response.text) > 200 else response.text
                }

            except Exception as e:
                results[url] = {"error": str(e)}

        return results

    def check_indexing_process(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            results = self.client.scroll(
                collection_name=self.collection,
                limit=10,
                with_payload=True
            )

            docs = results[0]

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_analysis = {
                "total_docs": len(docs),
                "has_content_field": 0,
                "has_title_field": 0,
                "has_url_field": 0,
                "content_types": {},
                "title_types": {},
                "indexed_via_values": {},
                "source_values": {},
                "language_values": {}
            }

            for doc in docs:
                payload = doc.payload

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–æ–ª–µ–π
                if 'content' in payload:
                    metadata_analysis["has_content_field"] += 1
                    content_type = type(payload['content']).__name__
                    metadata_analysis["content_types"][content_type] = metadata_analysis["content_types"].get(content_type, 0) + 1

                if 'title' in payload:
                    metadata_analysis["has_title_field"] += 1
                    title_type = type(payload['title']).__name__
                    metadata_analysis["title_types"][title_type] = metadata_analysis["title_types"].get(title_type, 0) + 1

                if 'url' in payload:
                    metadata_analysis["has_url_field"] += 1

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                indexed_via = payload.get('indexed_via', 'unknown')
                metadata_analysis["indexed_via_values"][indexed_via] = metadata_analysis["indexed_via_values"].get(indexed_via, 0) + 1

                source = payload.get('source', 'unknown')
                metadata_analysis["source_values"][source] = metadata_analysis["source_values"].get(source, 0) + 1

                language = payload.get('language', 'unknown')
                metadata_analysis["language_values"][language] = metadata_analysis["language_values"].get(language, 0) + 1

            return metadata_analysis

        except Exception as e:
            return {"error": str(e)}


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
    debugger = EncodingDebugger()

    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú –° –ö–û–î–ò–†–û–í–ö–û–ô")
    print("="*60)

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—ã—Ä–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    print("\n1Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ —Å—ã—Ä–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
    raw_docs = debugger.check_raw_content(5)

    for i, doc in enumerate(raw_docs, 1):
        if "error" in doc:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {doc['error']}")
            continue

        print(f"\n   üìÑ –î–æ–∫—É–º–µ–Ω—Ç {i}:")
        print(f"      URL: {doc['url']}")
        print(f"      –ó–∞–≥–æ–ª–æ–≤–æ–∫: {doc['title']}")
        print(f"      –¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {doc['raw_content_type']}")
        print(f"      –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {doc['raw_content_length']}")
        print(f"      –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: {doc['raw_content_repr']}")
        print(f"      –ö–ª—é—á–∏ payload: {doc['all_payload_keys']}")

        encoding_info = doc['encoding_info']
        if not encoding_info.get('is_empty', True):
            print(f"      –ö–æ–¥–∏—Ä–æ–≤–∫–∞:")
            for enc, info in encoding_info.get('encodings', {}).items():
                if info.get('success'):
                    print(f"         {enc}: ‚úÖ (–¥–ª–∏–Ω–∞: {info['length']})")
                    if info.get('preview'):
                        print(f"            –ü—Ä–µ–≤—å—é: {info['preview']}")
                else:
                    print(f"         {enc}: ‚ùå ({info.get('error', 'Unknown error')})")
        else:
            print(f"      ‚ùå –ö–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç–æ–π!")

    # 2. –¢–µ—Å—Ç–∏—Ä—É–µ–º Jina Reader
    print("\n2Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Jina Reader:")
    test_urls = [
        "https://docs-chatcenter.edna.ru/docs/start/whatis",
        "https://docs-chatcenter.edna.ru/docs/admin/widget/admin-widget-features"
    ]

    jina_results = debugger.test_jina_fetch(test_urls)

    for url, result in jina_results.items():
        if "error" in result:
            print(f"   ‚ùå {url}: {result['error']}")
        else:
            print(f"   üîç {url}:")
            print(f"      HTTP: {'‚úÖ' if result['http_success'] else '‚ùå'} (–∫–æ–¥: {result['status_code']})")
            print(f"      –î–ª–∏–Ω–∞: {result['content_length']} –±–∞–π—Ç")
            print(f"      –¢–∏–ø: {result['content_type']}")
            print(f"      –ö–æ–¥–∏—Ä–æ–≤–∫–∞: {result['encoding']}")
            print(f"      –ü—Ä–µ–≤—å—é: {result['preview']}")

    # 3. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    print("\n3Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:")
    indexing_analysis = debugger.check_indexing_process()

    if "error" not in indexing_analysis:
        print(f"   üìä –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {indexing_analysis['total_docs']}")
        print(f"   üìÑ –° –ø–æ–ª–µ–º content: {indexing_analysis['has_content_field']}")
        print(f"   üìù –° –ø–æ–ª–µ–º title: {indexing_analysis['has_title_field']}")
        print(f"   üîó –° –ø–æ–ª–µ–º url: {indexing_analysis['has_url_field']}")

        print(f"\n   üìã –¢–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞:")
        for content_type, count in indexing_analysis['content_types'].items():
            print(f"      {content_type}: {count}")

        print(f"\n   üìã –¢–∏–ø—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤:")
        for title_type, count in indexing_analysis['title_types'].items():
            print(f"      {title_type}: {count}")

        print(f"\n   üîß –ú–µ—Ç–æ–¥—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:")
        for method, count in indexing_analysis['indexed_via_values'].items():
            print(f"      {method}: {count}")

        print(f"\n   üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
        for source, count in indexing_analysis['source_values'].items():
            print(f"      {source}: {count}")

        print(f"\n   üåê –Ø–∑—ã–∫–∏:")
        for language, count in indexing_analysis['language_values'].items():
            print(f"      {language}: {count}")

    # 4. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º
    print("\n4Ô∏è‚É£ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º:")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –≤–æ–æ–±—â–µ
    has_content = any(doc.get('raw_content_length', 0) > 0 for doc in raw_docs if 'error' not in doc)
    if not has_content:
        print("   ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: –í–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç–æ–π!")
        print("   üí° –í–û–ó–ú–û–ñ–ù–´–ï –ü–†–ò–ß–ò–ù–´:")
        print("      - –°–∞–π—Ç –±–ª–æ–∫–∏—Ä—É–µ—Ç –±–æ—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Jina Reader)")
        print("      - –ü—Ä–æ–±–ª–µ–º–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ HTML")
        print("      - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞")
        print("      - –ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Jina Reader
    jina_used = any("jina" in str(method) for method in indexing_analysis.get('indexed_via_values', {}).keys())
    if not jina_used:
        print("   ‚ùå –ü–†–û–ë–õ–ï–ú–ê: Jina Reader –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        print("   üí° –†–ï–®–ï–ù–ò–ï: –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Å --strategy jina")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
    encoding_issues = []
    for doc in raw_docs:
        if 'error' not in doc:
            encoding_info = doc.get('encoding_info', {})
            if not encoding_info.get('is_empty', True):
                encodings = encoding_info.get('encodings', {})
                utf8_ok = encodings.get('utf-8', {}).get('success', False)
                if not utf8_ok:
                    encoding_issues.append(doc['url'])

    if encoding_issues:
        print(f"   ‚ùå –ü–†–û–ë–õ–ï–ú–ê: –ü—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –≤ {len(encoding_issues)} –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö")
        print("   üí° –†–ï–®–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")

    print("\n" + "="*60)
    print("‚úÖ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("="*60)


if __name__ == "__main__":
    asyncio.run(main())
