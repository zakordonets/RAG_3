#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ chunker'–∞.
"""

from __future__ import annotations

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from loguru import logger
from ingestion.chunker import chunk_text
from ingestion.crawl_cache import get_crawl_cache


def test_final_chunker():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é chunker'–∞."""
    logger.info("üéØ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ chunker'–∞")

    cache = get_crawl_cache()
    cached_urls = list(cache.get_cached_urls())

    if not cached_urls:
        logger.error("‚ùå –ù–µ—Ç –∑–∞–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return False

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ 5 —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö
    test_urls = cached_urls[:5]

    total_pages = 0
    total_chunks = 0
    chunk_sizes = []

    for url in test_urls:
        cached_page = cache.get_page(url)
        if not cached_page:
            continue

        chunks = chunk_text(cached_page.html)

        total_pages += 1
        total_chunks += len(chunks)

        logger.info(f"\nüìÑ {url}")
        logger.info(f"  –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(cached_page.html)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"  –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

        for i, chunk in enumerate(chunks, 1):
            tokens = len(chunk.split())
            chunk_sizes.append(tokens)
            status = "‚úÖ" if 60 <= tokens <= 250 else "‚ö†Ô∏è"
            logger.info(f"    –ß–∞–Ω–∫ {i}: {tokens} —Ç–æ–∫–µ–Ω–æ–≤ {status}")

    if chunk_sizes:
        avg_size = sum(chunk_sizes) / len(chunk_sizes)
        min_size = min(chunk_sizes)
        max_size = max(chunk_sizes)

        logger.info(f"\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        logger.info(f"  –°—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
        logger.info(f"  –ß–∞–Ω–∫–æ–≤: {total_chunks}")
        logger.info(f"  –ß–∞–Ω–∫–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {total_chunks/total_pages:.1f}")
        logger.info(f"  –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {avg_size:.0f} —Ç–æ–∫–µ–Ω–æ–≤")
        logger.info(f"  –î–∏–∞–ø–∞–∑–æ–Ω: {min_size}-{max_size} —Ç–æ–∫–µ–Ω–æ–≤")

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        optimal_chunks = sum(1 for size in chunk_sizes if 60 <= size <= 250)
        success_rate = optimal_chunks / len(chunk_sizes) * 100

        logger.info(f"  –û–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {optimal_chunks}/{len(chunk_sizes)} ({success_rate:.1f}%)")

        if success_rate >= 80:
            logger.success("‚úÖ Chunker —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
            return True
        elif success_rate >= 60:
            logger.warning("‚ö†Ô∏è Chunker —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏–µ–º–ª–µ–º–æ")
            return True
        else:
            logger.error("‚ùå Chunker —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
            return False

    return False


if __name__ == "__main__":
    success = test_final_chunker()
    sys.exit(0 if success else 1)
