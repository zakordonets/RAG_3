#!/usr/bin/env python3
"""
–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from app.services.retrieval import client, COLLECTION
from qdrant_client.models import Filter, FieldCondition, MatchValue
from datetime import datetime, date
import json

def cleanup_old_documents(dry_run=True):
    """–£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
    print("üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
    print("=" * 60)

    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        print("üìÑ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏...")
        all_results = client.scroll(
            collection_name=COLLECTION,
            limit=10000,  # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            with_payload=True,
            with_vectors=False
        )

        today = date.today().isoformat()
        old_documents = []
        today_documents = []

        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(all_results[0])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

        for point in all_results[0]:
            payload = point.payload
            indexed_at = payload.get('indexed_at', '')
            indexed_via = payload.get('indexed_via', 'unknown')
            content_length = payload.get('content_length', 0)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —É–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
            should_delete = False

            # –£–¥–∞–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å indexed_via: unknown
            if indexed_via == 'unknown':
                should_delete = True
                reason = "indexed_via: unknown"

            # –£–¥–∞–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å content_length: 0
            elif content_length == 0:
                should_delete = True
                reason = "content_length: 0"

            if should_delete:
                old_documents.append({
                    'id': point.id,
                    'url': payload.get('url', 'N/A'),
                    'title': payload.get('title', 'N/A'),
                    'reason': reason,
                    'indexed_via': indexed_via,
                    'content_length': content_length,
                    'indexed_at': indexed_at
                })
            else:
                today_documents.append({
                    'id': point.id,
                    'url': payload.get('url', 'N/A'),
                    'title': payload.get('title', 'N/A'),
                    'indexed_via': indexed_via,
                    'content_length': content_length,
                    'indexed_at': indexed_at
                })

        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   üóëÔ∏è  –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {len(old_documents)}")
        print(f"   ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {len(today_documents)}")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º —É–¥–∞–ª–µ–Ω–∏—è
        reasons = {}
        for doc in old_documents:
            reason = doc['reason']
            reasons[reason] = reasons.get(reason, 0) + 1

        print(f"\nüìã –ü—Ä–∏—á–∏–Ω—ã —É–¥–∞–ª–µ–Ω–∏—è:")
        for reason, count in reasons.items():
            print(f"   {reason}: {count}")

        if dry_run:
            print(f"\nüîç –†–ï–ñ–ò–ú –ü–†–û–°–ú–û–¢–†–ê (dry_run=True)")
            print("–î–æ–∫—É–º–µ–Ω—Ç—ã –ù–ï –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã. –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å dry_run=False")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            print(f"\nüìÑ –ü—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è:")
            for i, doc in enumerate(old_documents[:5]):
                print(f"   {i+1}. {doc['title']}")
                print(f"      URL: {doc['url']}")
                print(f"      –ü—Ä–∏—á–∏–Ω–∞: {doc['reason']}")
                print()
        else:
            print(f"\n‚ö†Ô∏è  –†–ï–ñ–ò–ú –£–î–ê–õ–ï–ù–ò–Ø (dry_run=False)")

            if len(old_documents) == 0:
                print("‚úÖ –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
                return

            # –£–¥–∞–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            print(f"üóëÔ∏è  –£–¥–∞–ª—è–µ–º {len(old_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            batch_size = 100
            deleted_count = 0

            for i in range(0, len(old_documents), batch_size):
                batch = old_documents[i:i + batch_size]
                point_ids = [doc['id'] for doc in batch]

                client.delete(
                    collection_name=COLLECTION,
                    points_selector=point_ids
                )

                deleted_count += len(batch)
                print(f"   –£–¥–∞–ª–µ–Ω–æ {deleted_count}/{len(old_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ {deleted_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = client.get_collection(COLLECTION)
            print(f"üìä –ù–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {collection_info.points_count}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse

    parser = argparse.ArgumentParser(description='–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ Qdrant')
    parser.add_argument('--execute', action='store_true',
                       help='–í—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å–º–æ—Ç—Ä)')

    args = parser.parse_args()

    dry_run = not args.execute

    if dry_run:
        print("üîç –†–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ - –¥–æ–∫—É–º–µ–Ω—Ç—ã –ù–ï –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã")
        print("–î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python scripts/cleanup_old_documents.py --execute")
        print()

    cleanup_old_documents(dry_run=dry_run)

if __name__ == "__main__":
    main()
