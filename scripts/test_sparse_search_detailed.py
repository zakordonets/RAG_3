#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ sparse –ø–æ–∏—Å–∫–∞
"""
import os
import sys
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.config import CONFIG
from app.services.bge_embeddings import embed_unified
from qdrant_client import QdrantClient
from qdrant_client.models import NamedSparseVector, SparseVector

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger.remove()
logger.add(sys.stderr, level="INFO")

def test_sparse_search_detailed():
    """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ sparse –ø–æ–∏—Å–∫–∞"""

    logger.info("üîç –î–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ sparse –ø–æ–∏—Å–∫–∞")
    logger.info("=" * 60)

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant
    client = QdrantClient(url=CONFIG.qdrant_url, api_key=CONFIG.qdrant_api_key or None)

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–ö–∞–∫ –º–Ω–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é?",
        "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏",
        "–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è",
        "routing configuration",
        "transfer thread",
        "API",
        "–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
    ]

    for i, query in enumerate(test_queries, 1):
        logger.info(f"\nüìù –¢–µ—Å—Ç {i}: '{query}'")
        logger.info("-" * 50)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings
        embedding_result = embed_unified(
            query,
            max_length=CONFIG.embedding_max_length_query,
            return_dense=True,
            return_sparse=CONFIG.use_sparse,
            return_colbert=False,
            context="query"
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º sparse –≤–µ–∫—Ç–æ—Ä
        q_sparse = {"indices": [], "values": []}
        if CONFIG.use_sparse and embedding_result.get('lexical_weights'):
            lex_weights = embedding_result['lexical_weights'][0]
            if lex_weights and isinstance(lex_weights, dict):
                indices = [int(k) for k in lex_weights.keys()]
                values = [float(lex_weights[k]) for k in lex_weights.keys()]
                q_sparse = {
                    "indices": indices,
                    "values": values
                }

        logger.info(f"üìä Sparse –≤–µ–∫—Ç–æ—Ä: {len(q_sparse['indices'])} –∏–Ω–¥–µ–∫—Å–æ–≤")
        if q_sparse['indices']:
            logger.info(f"üìã –ò–Ω–¥–µ–∫—Å—ã: {q_sparse['indices']}")
            logger.info(f"üìã –ó–Ω–∞—á–µ–Ω–∏—è: {[f'{v:.3f}' for v in q_sparse['values']]}")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ sparse –ø–æ–∏—Å–∫
        if q_sparse['indices'] and q_sparse['values']:
            try:
                sparse_vector = NamedSparseVector(
                    name="sparse",
                    vector=SparseVector(indices=q_sparse['indices'], values=q_sparse['values'])
                )

                sparse_res = client.search(
                    collection_name=CONFIG.qdrant_collection,
                    query_vector=sparse_vector,
                    with_payload=True,
                    limit=5,
                )

                logger.info(f"üìä Sparse –ø–æ–∏—Å–∫: {len(sparse_res)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                if sparse_res:
                    logger.info("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã sparse –ø–æ–∏—Å–∫–∞:")
                    for j, result in enumerate(sparse_res[:3], 1):
                        score = result.score if hasattr(result, 'score') else 'N/A'
                        doc_id = result.id if hasattr(result, 'id') else 'N/A'
                        logger.info(f"  {j}. ID: {doc_id}, Score: {score}")

                        if hasattr(result, 'payload') and result.payload and 'text' in result.payload:
                            text_preview = result.payload['text'][:100] + "..." if len(result.payload['text']) > 100 else result.payload['text']
                            logger.info(f"     Text: {text_preview}")
                else:
                    logger.warning("‚ö†Ô∏è Sparse –ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ sparse –ø–æ–∏—Å–∫–∞: {type(e).__name__}: {e}")
        else:
            logger.warning("‚ö†Ô∏è Sparse –≤–µ–∫—Ç–æ—Ä –ø—É—Å—Ç")

def test_sparse_indexing():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ sparse –≤–µ–∫—Ç–æ—Ä—ã –≤ –∏–Ω–¥–µ–∫—Å–µ"""

    logger.info("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ sparse –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ")
    logger.info("=" * 60)

    client = QdrantClient(url=CONFIG.qdrant_url, api_key=CONFIG.qdrant_api_key or None)

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collection_info = client.get_collection(CONFIG.qdrant_collection)
        logger.info(f"üìä –ö–æ–ª–ª–µ–∫—Ü–∏—è: {CONFIG.qdrant_collection}")
        logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫: {collection_info.points_count}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–µ–º—É –≤–µ–∫—Ç–æ—Ä–æ–≤
        if hasattr(collection_info, 'config') and hasattr(collection_info.config, 'params'):
            params = collection_info.config.params
            if hasattr(params, 'vectors') and hasattr(params.vectors, 'sparse_vectors'):
                sparse_config = params.vectors.sparse_vectors
                logger.info(f"üìä Sparse –≤–µ–∫—Ç–æ—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã: {sparse_config}")
            else:
                logger.warning("‚ö†Ô∏è Sparse –≤–µ–∫—Ç–æ—Ä—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")

        # –ü–æ–ª—É—á–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ—á–µ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        points = client.scroll(
            collection_name=CONFIG.qdrant_collection,
            limit=3,
            with_payload=True,
            with_vectors=True
        )[0]

        logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(points)} —Ç–æ—á–µ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")

        for i, point in enumerate(points):
            logger.info(f"\nüìã –¢–æ—á–∫–∞ {i+1}:")
            logger.info(f"  ID: {point.id}")

            if hasattr(point, 'vector') and point.vector:
                if isinstance(point.vector, dict):
                    logger.info(f"  –í–µ–∫—Ç–æ—Ä—ã: {list(point.vector.keys())}")
                    if 'sparse' in point.vector:
                        sparse_vec = point.vector['sparse']
                        if hasattr(sparse_vec, 'indices') and hasattr(sparse_vec, 'values'):
                            logger.info(f"  Sparse: {len(sparse_vec.indices)} –∏–Ω–¥–µ–∫—Å–æ–≤, {len(sparse_vec.values)} –∑–Ω–∞—á–µ–Ω–∏–π")
                            if sparse_vec.indices:
                                logger.info(f"    –ò–Ω–¥–µ–∫—Å—ã: {sparse_vec.indices[:10]}...")
                                logger.info(f"    –ó–Ω–∞—á–µ–Ω–∏—è: {[f'{v:.3f}' for v in sparse_vec.values[:10]]}...")
                        else:
                            logger.info(f"  Sparse: {sparse_vec}")
                    else:
                        logger.warning("  ‚ö†Ô∏è Sparse –≤–µ–∫—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
                else:
                    logger.info(f"  –í–µ–∫—Ç–æ—Ä: {type(point.vector)}")
            else:
                logger.warning("  ‚ö†Ô∏è –í–µ–∫—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏–Ω–¥–µ–∫—Å–∞: {type(e).__name__}: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    test_sparse_search_detailed()
    test_sparse_indexing()
