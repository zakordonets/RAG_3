#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–∫–∞ sparse –ø–æ–∏—Å–∫–∞
"""
import os
import sys
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.config import CONFIG
from app.services.bge_embeddings import embed_unified
from app.services.retrieval import hybrid_search

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger.remove()
logger.add(sys.stderr, level="INFO")

def test_sparse_search_debug():
    """–û—Ç–ª–∞–∂–∏–≤–∞–µ—Ç sparse –ø–æ–∏—Å–∫"""

    logger.info("üîç –û—Ç–ª–∞–¥–∫–∞ sparse –ø–æ–∏—Å–∫–∞")
    logger.info("=" * 50)

    query = "–ö–∞–∫ –º–Ω–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é?"

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embeddings
    logger.info(f"üìù –ó–∞–ø—Ä–æ—Å: '{query}'")

    embedding_result = embed_unified(
        query,
        max_length=CONFIG.embedding_max_length_query,
        return_dense=True,
        return_sparse=CONFIG.use_sparse,
        return_colbert=False,
        context="query"
    )

    logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç embed_unified:")
    logger.info(f"  - dense_vecs: {len(embedding_result.get('dense_vecs', []))}")
    logger.info(f"  - sparse_vecs: {len(embedding_result.get('sparse_vecs', []))}")
    logger.info(f"  - lexical_weights: {len(embedding_result.get('lexical_weights', []))}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º dense –≤–µ–∫—Ç–æ—Ä
    q_dense = embedding_result['dense_vecs'][0] if embedding_result.get('dense_vecs') else []
    logger.info(f"üìè Dense —Ä–∞–∑–º–µ—Ä: {len(q_dense)}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º sparse –≤–µ–∫—Ç–æ—Ä
    q_sparse = {"indices": [], "values": []}
    if CONFIG.use_sparse and embedding_result.get('lexical_weights'):
        lex_weights = embedding_result['lexical_weights'][0]
        if lex_weights and isinstance(lex_weights, dict):
            indices = [int(k) for k in lex_weights.keys()]
            values = [float(lex_weights[k]) for k in lex_weights.keys()]
            q_sparse = {
                "indices": indices,
                "values": values
            }
            logger.info(f"üìè Sparse —Ä–∞–∑–º–µ—Ä: {len(indices)} –∏–Ω–¥–µ–∫—Å–æ–≤, {len(values)} –∑–Ω–∞—á–µ–Ω–∏–π")
            logger.info(f"üìã Sparse –∏–Ω–¥–µ–∫—Å—ã: {indices}")
            logger.info(f"üìã Sparse –∑–Ω–∞—á–µ–Ω–∏—è: {values}")
        else:
            logger.warning("‚ö†Ô∏è lexical_weights –ø—É—Å—Ç—ã –∏–ª–∏ –Ω–µ —Å–ª–æ–≤–∞—Ä—å")
    else:
        logger.warning("‚ö†Ô∏è use_sparse=False –∏–ª–∏ lexical_weights –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    logger.info(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º hybrid_search...")
    try:
        results = hybrid_search(q_dense, q_sparse, k=10)
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: {len(results)}")

        if results:
            logger.info("üìã –ü–µ—Ä–≤—ã–µ 3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
            for i, result in enumerate(results[:3]):
                logger.info(f"  {i+1}. ID: {result.get('id', 'N/A')}, Score: {result.get('score', 'N/A')}")
                if 'payload' in result and 'text' in result['payload']:
                    text_preview = result['payload']['text'][:100] + "..." if len(result['payload']['text']) > 100 else result['payload']['text']
                    logger.info(f"     Text: {text_preview}")
        else:
            logger.warning("‚ö†Ô∏è –ü–æ–∏—Å–∫ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {type(e).__name__}: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    test_sparse_search_debug()
