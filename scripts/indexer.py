#!/usr/bin/env python3
"""
Production –º–æ–¥—É–ª—å –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ edna Chat Center

–ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ production —Å—Ä–µ–¥–µ.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É.
"""

import sys
import os
import argparse
from typing import Optional, Dict, Any
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from qdrant_client import QdrantClient
from urllib.parse import urlparse

from app.config import CONFIG
from ingestion.pipeline import crawl_and_index


class Indexer:
    """Production –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π"""

    def __init__(self):
        self.client = self._get_qdrant_client()

    def _get_qdrant_client(self) -> QdrantClient:
        """–°–æ–∑–¥–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç Qdrant"""
        parsed = urlparse(CONFIG.qdrant_url)
        return QdrantClient(
            host=parsed.hostname,
            port=parsed.port or 6333,
            prefer_grpc=CONFIG.qdrant_grpc
        )

    def status(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = self.client.get_collection(CONFIG.qdrant_collection)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º sparse –≤–µ–∫—Ç–æ—Ä—ã –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–æ—á–∫–∞—Ö
            points = self.client.scroll(
                collection_name=CONFIG.qdrant_collection,
                limit=10,
                with_vectors=True
            )[0]

            sparse_coverage = 0
            if points:
                sparse_count = sum(
                    1 for p in points
                    if hasattr(p, 'vector') and isinstance(p.vector, dict) and 'sparse' in p.vector
                )
                sparse_coverage = (sparse_count / len(points)) * 100

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embedding_dim = "unknown"
            has_sparse_config = False

            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º named vectors (–Ω–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
                if hasattr(collection_info.config.params, 'vectors') and collection_info.config.params.vectors:
                    vectors_config = collection_info.config.params.vectors
                    if hasattr(vectors_config, 'get'):
                        # –≠—Ç–æ dict
                        if "dense" in vectors_config:
                            embedding_dim = vectors_config["dense"].size
                        has_sparse_config = "sparse" in vectors_config
                    else:
                        # –≠—Ç–æ VectorParams (—Å—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
                        embedding_dim = vectors_config.size
            except Exception:
                # Fallback - –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏
                if points:
                    try:
                        if hasattr(points[0], 'vector'):
                            if isinstance(points[0].vector, dict) and 'dense' in points[0].vector:
                                embedding_dim = len(points[0].vector['dense'])
                            elif isinstance(points[0].vector, list):
                                embedding_dim = len(points[0].vector)
                    except Exception:
                        pass

            return {
                "collection_exists": True,
                "total_points": collection_info.points_count,
                "sparse_coverage": sparse_coverage,
                "embedding_dim": embedding_dim,
                "has_sparse_config": has_sparse_config,
                "backend": CONFIG.embeddings_backend,
                "use_sparse": CONFIG.use_sparse,
                "chunk_config": f"{CONFIG.chunk_min_tokens}-{CONFIG.chunk_max_tokens} tokens"
            }
        except Exception as e:
            return {
                "collection_exists": False,
                "error": str(e)
            }

    def reindex(self,
                mode: str = "auto",
                strategy: str = "jina",
                use_cache: bool = True,
                max_pages: Optional[int] = None,
                force_full: bool = False,
                sparse: bool = True,
                backend: str = "auto") -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é

        Args:
            mode: –†–µ–∂–∏–º –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (auto, full, incremental, cache_only)
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∫—Ä–∞—É–ª–∏–Ω–≥–∞ (jina, browser, http)
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à
            max_pages: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
            force_full: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å API)
            sparse: –í–∫–ª—é—á–∏—Ç—å sparse –≤–µ–∫—Ç–æ—Ä—ã
            backend: Backend –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (auto, onnx, bge, hybrid)
        """
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –≤ —Ä–µ–∂–∏–º–µ '{mode}'")
        logger.info(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: strategy={strategy}, use_cache={use_cache}, max_pages={max_pages}")
        logger.info(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: sparse={sparse}, backend={backend}")

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        import os
        # Sparse –≤–µ–∫—Ç–æ—Ä—ã –≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω—ã –≤ production
        os.environ["USE_SPARSE"] = "true"
        if backend != "auto":
            os.environ["EMBEDDINGS_BACKEND"] = backend

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:")
        logger.info(f"  EMBEDDINGS_BACKEND: {CONFIG.embeddings_backend}")
        logger.info(f"  EMBEDDING_DEVICE: {CONFIG.embedding_device}")
        logger.info(f"  USE_SPARSE: {CONFIG.use_sparse}")
        logger.info(f"  EMBEDDING_MAX_LENGTH_DOC: {CONFIG.embedding_max_length_doc}")
        logger.info(f"  EMBEDDING_BATCH_SIZE: {CONFIG.embedding_batch_size}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è crawl_and_index
        if mode == "full" or force_full:
            incremental = False
            reindex_mode = "auto"
        elif mode == "incremental":
            incremental = True
            reindex_mode = "auto"
        elif mode == "cache_only":
            incremental = True
            reindex_mode = "cache_only"
        else:  # auto
            incremental = True
            reindex_mode = "auto"

        try:
            result = crawl_and_index(
                incremental=incremental,
                strategy=strategy,
                use_cache=use_cache,
                reindex_mode=reindex_mode,
                max_pages=max_pages
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            new_status = self.status()

            logger.success("‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
            logger.info(f"üìà –ù–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {new_status['total_points']} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            return {
                "success": True,
                "result": result,
                "new_status": new_status
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def init_collection(self, recreate: bool = False) -> Dict[str, Any]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant"""
        try:
            if recreate:
                logger.info("üîÑ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
                from scripts.init_qdrant import main as init_main
                init_main()
                logger.success("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞")
            else:
                logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
                from scripts.init_qdrant import main as init_main
                init_main()
                logger.success("‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

            return {"success": True}

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return {"success": False, "error": str(e)}


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    parser = argparse.ArgumentParser(
        description="Production –º–æ–¥—É–ª—å –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ edna Chat Center",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
  python scripts/indexer.py status

  # –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
  python scripts/indexer.py reindex --mode full

  # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
  python scripts/indexer.py reindex --mode incremental

  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
  python scripts/indexer.py reindex --mode cache_only

  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
  python scripts/indexer.py init

  # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
  python scripts/indexer.py init --recreate

  # –¢–µ—Å—Ç–æ–≤–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ 5 —Å—Ç—Ä–∞–Ω–∏—Ü)
  python scripts/indexer.py reindex --mode full --max-pages 5
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã')

    # –ö–æ–º–∞–Ω–¥–∞ status
    status_parser = subparsers.add_parser('status', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã')

    # –ö–æ–º–∞–Ω–¥–∞ reindex
    reindex_parser = subparsers.add_parser('reindex', help='–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é')
    reindex_parser.add_argument(
        '--mode',
        choices=['auto', 'full', 'incremental', 'cache_only'],
        default='auto',
        help='–†–µ–∂–∏–º –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: auto)'
    )
    reindex_parser.add_argument(
        '--strategy',
        choices=['jina', 'browser', 'http'],
        default='jina',
        help='–°—Ç—Ä–∞—Ç–µ–≥–∏—è –∫—Ä–∞—É–ª–∏–Ω–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: jina)'
    )
    reindex_parser.add_argument(
        '--no-cache',
        action='store_true',
        help='–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à'
    )
    reindex_parser.add_argument(
        '--max-pages',
        type=int,
        help='–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)'
    )
    reindex_parser.add_argument(
        '--sparse',
        action='store_true',
        default=True,
        help='–í–∫–ª—é—á–∏—Ç—å sparse –≤–µ–∫—Ç–æ—Ä—ã (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω–æ)'
    )
    reindex_parser.add_argument(
        '--backend',
        choices=['auto', 'onnx', 'bge', 'hybrid'],
        default='auto',
        help='Backend –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: auto)'
    )
    reindex_parser.add_argument(
        '--batch-size',
        type=int,
        default=16,
        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 16)'
    )
    reindex_parser.add_argument(
        '--max-length',
        type=int,
        default=1024,
        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1024)'
    )

    # –ö–æ–º–∞–Ω–¥–∞ init
    init_parser = subparsers.add_parser('init', help='–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é')
    init_parser.add_argument(
        '--recreate',
        action='store_true',
        help='–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é'
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logger.remove()
    logger.add(
        sys.stderr,
        level="INFO",
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
    )

    indexer = Indexer()

    try:
        if args.command == 'status':
            status = indexer.status()

            print("\nüìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            print("=" * 50)

            if status.get("collection_exists"):
                print(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è: {CONFIG.qdrant_collection}")
                print(f"üìà –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {status['total_points']}")
                print(f"üéØ Sparse –ø–æ–∫—Ä—ã—Ç–∏–µ: {status['sparse_coverage']:.1f}%")
                print(f"üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {status['embedding_dim']}")
                print(f"‚öôÔ∏è Backend: {status['backend']}")
                print(f"üîß Sparse –≤–µ–∫—Ç–æ—Ä—ã: {'–≤–∫–ª—é—á–µ–Ω—ã' if status['use_sparse'] else '–æ—Ç–∫–ª—é—á–µ–Ω—ã'}")
                print(f"üìù Chunking: {status['chunk_config']}")

                if status['sparse_coverage'] < 100:
                    print("\n‚ö†Ô∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–ª—è 100% sparse –ø–æ–∫—Ä—ã—Ç–∏—è")
                else:
                    print("\n‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞: {status.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                print("\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: python scripts/indexer.py init")
                return 1

        elif args.command == 'reindex':
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è batch-size –∏ max-length
            os.environ["EMBEDDING_BATCH_SIZE"] = str(args.batch_size)
            os.environ["EMBEDDING_MAX_LENGTH_DOC"] = str(args.max_length)

            result = indexer.reindex(
                mode=args.mode,
                strategy=args.strategy,
                use_cache=not args.no_cache,
                max_pages=args.max_pages,
                sparse=args.sparse,
                backend=args.backend
            )

            if result['success']:
                print("\n‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                return 0
            else:
                print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                return 1

        elif args.command == 'init':
            result = indexer.init_collection(recreate=args.recreate)

            if result['success']:
                print("\n‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
                return 0
            else:
                print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                return 1

    except KeyboardInterrupt:
        logger.warning("‚èπÔ∏è –û–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 130
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 1


if __name__ == "__main__":
    sys.exit(main())
