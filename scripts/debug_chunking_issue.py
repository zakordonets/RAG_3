#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —á–∞–Ω–∫–æ–≤
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

import time
from app.abstractions.data_source import plugin_manager
from app.services.optimized_pipeline import OptimizedPipeline
from ingestion.chunker import chunk_text
from app.config import CONFIG

# Import data sources
from app.sources import edna_docs_source


def debug_single_page():
    """–û—Ç–ª–∞–¥–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –û–î–ù–û–ô –°–¢–†–ê–ù–ò–¶–´")
    print("=" * 50)

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö
        edna_config = {
            "base_url": "https://docs-chatcenter.edna.ru/",
            "strategy": "jina",
            "use_cache": True,
            "max_pages": 1
        }

        source = plugin_manager.get_source("edna_docs", edna_config)
        crawl_result = source.fetch_pages(max_pages=1)

        if not crawl_result.pages:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
            return

        page = crawl_result.pages[0]
        print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞: {page.title}")
        print(f"   URL: {page.url}")
        print(f"   –¢–∏–ø: {page.page_type.value}")
        print(f"   –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(page.content)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {page.content[:200]}...")

        # –¢–µ—Å—Ç chunking
        print(f"\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ chunking:")
        print(f"   Chunk min tokens: {CONFIG.chunk_min_tokens}")
        print(f"   Chunk max tokens: {CONFIG.chunk_max_tokens}")

        chunks = chunk_text(page.content)
        print(f"   –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

        if chunks:
            for i, chunk in enumerate(chunks[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —á–∞–Ω–∫–∞
                print(f"   –ß–∞–Ω–∫ {i+1}: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"      –ù–∞—á–∞–ª–æ: {chunk[:100]}...")
        else:
            print("   ‚ùå –ß–∞–Ω–∫–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
            print(f"\nüîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:")
            print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç–æ–π? {len(page.content) == 0}")
            print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã? {page.content.strip() == ''}")
            print(f"   –ö–æ–Ω—Ç–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç HTML? {'<' in page.content and '>' in page.content}")

            # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ chunking
            print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π chunking:")

            # –¢–µ—Å—Ç —Å –º–µ–Ω—å—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            try:
                from ingestion.chunker import chunk_text
                chunks_small = chunk_text(page.content, max_tokens=50)
                print(f"   –° max_tokens=50: {len(chunks_small)} —á–∞–Ω–∫–æ–≤")
            except Exception as e:
                print(f"   –û—à–∏–±–∫–∞ —Å max_tokens=50: {e}")

            # –¢–µ—Å—Ç —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º chunking
            try:
                text_words = page.content.split()
                if text_words:
                    # –ü—Ä–æ—Å—Ç–æ–π chunking –ø–æ —Å–ª–æ–≤–∞–º
                    simple_chunks = []
                    chunk_size = 100  # —Å–ª–æ–≤
                    for i in range(0, len(text_words), chunk_size):
                        chunk = ' '.join(text_words[i:i+chunk_size])
                        simple_chunks.append(chunk)
                    print(f"   –ü—Ä–æ—Å—Ç–æ–π chunking (100 —Å–ª–æ–≤): {len(simple_chunks)} —á–∞–Ω–∫–æ–≤")
                else:
                    print(f"   –ù–µ—Ç —Å–ª–æ–≤ –¥–ª—è chunking")
            except Exception as e:
                print(f"   –û—à–∏–±–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ chunking: {e}")

        return len(chunks) > 0

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return False


def debug_chunking_function():
    """–û—Ç–ª–∞–¥–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ chunking –Ω–∞–ø—Ä—è–º—É—é"""
    print("\nüîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –§–£–ù–ö–¶–ò–ò CHUNKING")
    print("=" * 50)

    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    test_texts = [
        "–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è chunking —Ñ—É–Ω–∫—Ü–∏–∏.",
        "–≠—Ç–æ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤. " * 50,
        "",  # –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
        "   ",  # –¢–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã
        "–û–¥–∏–Ω –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤." * 100
    ]

    for i, text in enumerate(test_texts):
        print(f"\nüìù –¢–µ—Å—Ç {i+1}:")
        print(f"   –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –¢–µ–∫—Å—Ç: {text[:50]}{'...' if len(text) > 50 else ''}")

        try:
            chunks = chunk_text(text)
            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(chunks)} —á–∞–Ω–∫–æ–≤")
            if chunks:
                for j, chunk in enumerate(chunks[:2]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 —á–∞–Ω–∫–∞
                    print(f"      –ß–∞–Ω–∫ {j+1}: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤")
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")


def debug_pipeline_processing():
    """–û—Ç–ª–∞–¥–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ pipeline"""
    print("\nüîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê PIPELINE –û–ë–†–ê–ë–û–¢–ö–ò")
    print("=" * 50)

    try:
        pipeline = OptimizedPipeline()

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        from app.abstractions.data_source import Page, PageType

        test_page = Page(
            url="https://test.com/test",
            title="Test Page",
            content="–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ pipeline. " * 20,  # –î–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            page_type=PageType.GUIDE,
            metadata={},
            source="test",
            size_bytes=1000
        )

        print(f"üìÑ –¢–µ—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞:")
        print(f"   –î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(test_page.content)}")
        print(f"   –†–∞–∑–º–µ—Ä: {test_page.size_bytes} –±–∞–π—Ç")

        # –¢–µ—Å—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ chunking
        chunks = pipeline._adaptive_chunk_page(test_page)
        print(f"   –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π chunking: {len(chunks)} —á–∞–Ω–∫–æ–≤")

        # –¢–µ—Å—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ chunking
        chunks_std = pipeline._standard_chunk_page(test_page)
        print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π chunking: {len(chunks_std)} —á–∞–Ω–∫–æ–≤")

        # –¢–µ—Å—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–∞
        optimal_size = pipeline._get_optimal_chunk_size(test_page)
        print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {optimal_size}")

        return len(chunks) > 0 or len(chunks_std) > 0

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    print("üöÄ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú–´ –° CHUNKING")
    print("=" * 80)

    results = []

    # –¢–µ—Å—Ç 1: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    result1 = debug_single_page()
    results.append(("–°—Ç—Ä–∞–Ω–∏—Ü–∞", result1))

    # –¢–µ—Å—Ç 2: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ chunking
    debug_chunking_function()
    results.append(("–§—É–Ω–∫—Ü–∏—è chunking", True))  # –ï—Å–ª–∏ –Ω–µ —É–ø–∞–ª–∞, —Ç–æ OK

    # –¢–µ—Å—Ç 3: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏
    result3 = debug_pipeline_processing()
    results.append(("Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∞", result3))

    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 80)
    print("üìä –ò–¢–û–ì–ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
    print("=" * 80)

    for test_name, result in results:
        status = "‚úÖ" if result else "‚ùå"
        print(f"{status} {test_name}: {'OK' if result else '–ü—Ä–æ–±–ª–µ–º–∞'}")

    successful_tests = sum(1 for _, result in results if result)
    print(f"\nüìà –ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {successful_tests}/{len(results)}")

    if successful_tests == len(results):
        print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã! –ü—Ä–æ–±–ª–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ.")
    else:
        print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã, —Ç—Ä–µ–±—É—é—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è.")


if __name__ == "__main__":
    main()
