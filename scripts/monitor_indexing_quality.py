#!/usr/bin/env python3
"""
–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
"""
import asyncio
import time
import sys
from typing import Dict, List
from pathlib import Path
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é app
sys.path.append(str(Path(__file__).parent.parent))

from app.services.retrieval import client, COLLECTION
from app.services.bge_embeddings import embed_unified
from app.services.retrieval import hybrid_search
from app.services.rerank import rerank
from qdrant_client.models import Filter


class IndexingQualityMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""

    def __init__(self):
        self.collection = COLLECTION
        self.client = client
        self.test_queries = [
            "–ö–∞–∫–∏–µ –∫–∞–Ω–∞–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤ —á–∞—Ç-—Ü–µ–Ω—Ç—Ä–µ?",
            "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Telegram –±–æ—Ç–∞?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–µ–±-–≤–∏–¥–∂–µ—Ç?",
            "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç edna Chat Center?",
            "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏"
        ]

    async def check_russian_content_percentage(self) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ä—É—Å—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º"""
        try:
            results = self.client.scroll(
                collection_name=self.collection,
                limit=100,
                with_payload=True
            )

            docs = results[0]
            russian_docs = 0

            for doc in docs:
                content = str(doc.payload.get("content", ""))
                if content and any(ord(c) > 127 for c in content[:200]):
                    russian_docs += 1

            return (russian_docs / len(docs) * 100) if docs else 0

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä—É—Å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            return 0

    async def check_key_terms_availability(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        key_terms = ["–∫–∞–Ω–∞–ª", "telegram", "–≤–∏–¥–∂–µ—Ç", "—á–∞—Ç-—Ü–µ–Ω—Ç—Ä", "edna"]
        results = {}

        for term in key_terms:
            try:
                filter_result = self.client.scroll(
                    collection_name=self.collection,
                    scroll_filter=Filter(
                        must=[
                            {'key': 'content', 'match': {'text': term}}
                        ]
                    ),
                    limit=1,
                    with_payload=True
                )
                results[term] = len(filter_result[0]) > 0
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ç–µ—Ä–º–∏–Ω–∞ '{term}': {e}")
                results[term] = False

        return results

    async def test_search_quality(self) -> Dict[str, float]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞"""
        results = {}

        for query in self.test_queries:
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                embeddings = embed_unified(query, return_dense=True, return_sparse=True)

                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
                search_results = hybrid_search(
                    query_dense=embeddings['dense_vecs'][0],
                    query_sparse=embeddings['sparse_vecs'][0],
                    k=10
                )

                # –†–µ—Ä–∞–Ω–∫–∏–Ω–≥
                reranked = rerank(query, search_results, top_n=5)

                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                quality_score = min(1.0, len(reranked) / 5.0)
                results[query] = quality_score

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ–∏—Å–∫–∞ –¥–ª—è '{query}': {e}")
                results[query] = 0.0

        return results

    async def get_health_status(self) -> Dict[str, any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è –∏–Ω–¥–µ–∫—Å–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            info = self.client.get_collection(self.collection)
            total_docs = info.points_count

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Ä—É—Å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            russian_pct = await self.check_russian_content_percentage()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            key_terms = await self.check_key_terms_availability()
            available_terms = sum(key_terms.values())
            total_terms = len(key_terms)

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞
            search_quality = await self.test_search_quality()
            avg_search_quality = sum(search_quality.values()) / len(search_quality)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
            if russian_pct >= 80 and available_terms >= total_terms * 0.8 and avg_search_quality >= 0.7:
                status = "HEALTHY"
                status_emoji = "‚úÖ"
            elif russian_pct >= 50 and available_terms >= total_terms * 0.5 and avg_search_quality >= 0.5:
                status = "WARNING"
                status_emoji = "‚ö†Ô∏è"
            else:
                status = "CRITICAL"
                status_emoji = "‚ùå"

            return {
                "status": status,
                "status_emoji": status_emoji,
                "total_documents": total_docs,
                "russian_content_percentage": russian_pct,
                "key_terms_available": f"{available_terms}/{total_terms}",
                "average_search_quality": avg_search_quality,
                "key_terms_details": key_terms,
                "search_quality_details": search_quality,
                "timestamp": time.time()
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–¥–æ—Ä–æ–≤—å—è: {e}")
            return {
                "status": "ERROR",
                "status_emoji": "üí•",
                "error": str(e),
                "timestamp": time.time()
            }

    async def monitor_continuously(self, interval: int = 300):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º"""
        logger.info(f"üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval} —Å–µ–∫—É–Ω–¥")

        while True:
            try:
                health = await self.get_health_status()

                print(f"\n{health['status_emoji']} –°–¢–ê–¢–£–° –ò–ù–î–ï–ö–°–ê: {health['status']}")
                print(f"üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {health.get('total_documents', 'N/A')}")
                print(f"üá∑üá∫ –†—É—Å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç: {health.get('russian_content_percentage', 0):.1f}%")
                print(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {health.get('key_terms_available', 'N/A')}")
                print(f"üîç –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞: {health.get('average_search_quality', 0):.2f}")

                if health['status'] == 'CRITICAL':
                    print("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –°–¢–ê–¢–£–°! –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è!")
                elif health['status'] == 'WARNING':
                    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï! –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è.")
                else:
                    print("‚úÖ –í—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ!")

                # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                await asyncio.sleep(interval)

            except KeyboardInterrupt:
                print("\nüõë –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ: {e}")
                await asyncio.sleep(interval)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    monitor = IndexingQualityMonitor()

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å
    health = await monitor.get_health_status()

    print("="*60)
    print("üìä –ú–û–ù–ò–¢–û–†–ò–ù–ì –ö–ê–ß–ï–°–¢–í–ê –ò–ù–î–ï–ö–°–ê–¶–ò–ò")
    print("="*60)

    print(f"\n{health['status_emoji']} –°–¢–ê–¢–£–°: {health['status']}")

    if 'error' not in health:
        print(f"üìä –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {health['total_documents']}")
        print(f"üá∑üá∫ –†—É—Å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç: {health['russian_content_percentage']:.1f}%")
        print(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {health['key_terms_available']}")
        print(f"üîç –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞: {health['average_search_quality']:.2f}")

        print(f"\nüîë –î–ï–¢–ê–õ–ò –ö–õ–Æ–ß–ï–í–´–• –¢–ï–†–ú–ò–ù–û–í:")
        for term, available in health['key_terms_details'].items():
            print(f"   {'‚úÖ' if available else '‚ùå'} {term}")

        print(f"\nüîç –î–ï–¢–ê–õ–ò –ö–ê–ß–ï–°–¢–í–ê –ü–û–ò–°–ö–ê:")
        for query, quality in health['search_quality_details'].items():
            print(f"   {quality:.2f} {query}")

    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {health['error']}")

    print("="*60)

    # –°–ø—Ä–∞—à–∏–≤–∞–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    try:
        response = input("\nüîÑ –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥? (y/n): ").lower().strip()
        if response in ['y', 'yes', '–¥–∞']:
            await monitor.monitor_continuously(interval=300)  # 5 –º–∏–Ω—É—Ç
    except KeyboardInterrupt:
        print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")


if __name__ == "__main__":
    asyncio.run(main())
